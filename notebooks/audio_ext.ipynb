{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d85675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from src.music_recommender.config import Config\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Any\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    explained_variance_score,\n",
    "    mean_absolute_percentage_error,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    balanced_accuracy_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from loguru import logger\n",
    "from scipy.signal import find_peaks\n",
    "import hashlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    mutual_info_regression,\n",
    "    VarianceThreshold,\n",
    ")\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "import pickle\n",
    "import io\n",
    "import json\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4287784",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "asp = cfg.paths.processed / \"audio\"\n",
    "prc = cfg.paths.processed\n",
    "intr = cfg.paths.interim\n",
    "mdl = cfg.paths.models\n",
    "rep = cfg.paths.reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6417cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioLoader(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sr: int = 22050):\n",
    "        self.sr = sr\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        X can be:\n",
    "        - pd.Series of file paths (training)\n",
    "        - List of file paths (training)\n",
    "        - Single file path (inference)\n",
    "        - List of bytes objects (inference - uploaded files)\n",
    "        - Single bytes object (inference)\n",
    "        \"\"\"\n",
    "        if isinstance(X, (str, Path)):\n",
    "            X = [X]\n",
    "        elif isinstance(X, bytes):\n",
    "            X = [X]\n",
    "        elif hasattr(X, \"tolist\"):\n",
    "            X = X.tolist()\n",
    "\n",
    "        results = []\n",
    "        for item in tqdm(X, desc=\"Loading audio\"):\n",
    "            loaded = self._load_single(item)\n",
    "            results.append(loaded)\n",
    "\n",
    "        return np.array(results, dtype=object)\n",
    "\n",
    "    def _load_single(self, item):\n",
    "        \"\"\"\n",
    "        Returns dict with: audio, sr, path (or pseudo-path for caching)\n",
    "        \"\"\"\n",
    "        if isinstance(item, (str, Path)):\n",
    "            # Training mode: load from path\n",
    "            audio, sr = librosa.load(item, sr=self.sr)\n",
    "            return {\"audio\": audio, \"sr\": sr, \"path\": Path(item), \"source_type\": \"path\"}\n",
    "\n",
    "        elif isinstance(item, bytes):\n",
    "            audio, sr = librosa.load(io.BytesIO(item), sr=self.sr)\n",
    "\n",
    "            audio_hash = hashlib.md5(item[:10000]).hexdigest()\n",
    "            pseudo_path = Path(f\"uploaded_{audio_hash}\")\n",
    "\n",
    "            return {\n",
    "                \"audio\": audio,\n",
    "                \"sr\": sr,\n",
    "                \"path\": pseudo_path,\n",
    "                \"source_type\": \"bytes\",\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input type: {type(item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fac987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        new_sr: int = 22050,\n",
    "        new_ch: int = 1,\n",
    "        n_fft: int = 2048,\n",
    "        hop_length: int = 512,\n",
    "        n_mels: int = 40,\n",
    "        target_duration: float = 30.0,\n",
    "        cache_dir: Path = None,\n",
    "        save_cache: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.new_ch = new_ch\n",
    "        self.new_sr = new_sr\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.target_duration = target_duration\n",
    "        self.cache_dir = cache_dir\n",
    "        self.save_cache = save_cache\n",
    "        if save_cache and cache_dir:\n",
    "            cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _resample(\n",
    "        aud_sr: tuple[np.ndarray, float], new_sr: int\n",
    "    ) -> tuple[np.ndarray, float]:\n",
    "        aud, sr = aud_sr\n",
    "        if sr == new_sr:\n",
    "            return aud, sr\n",
    "        if aud.ndim == 1:\n",
    "            res_aud = librosa.resample(aud, orig_sr=sr, target_sr=new_sr)\n",
    "        else:\n",
    "            res_aud = np.stack(\n",
    "                [\n",
    "                    librosa.resample(channel, orig_sr=sr, target_sr=new_sr)\n",
    "                    for channel in aud\n",
    "                ]\n",
    "            )\n",
    "        return res_aud, new_sr\n",
    "\n",
    "    @staticmethod\n",
    "    def _rechannel(\n",
    "        aud_sr: tuple[np.ndarray, float], new_ch: int\n",
    "    ) -> tuple[np.ndarray, float]:\n",
    "        aud, sr = aud_sr\n",
    "        n_ch = 1 if aud.ndim == 1 else aud.shape[0]\n",
    "        if n_ch == new_ch:\n",
    "            return aud_sr\n",
    "        if new_ch == 1:\n",
    "            res_aud = np.mean(aud, axis=0, keepdims=True)\n",
    "            return res_aud, sr\n",
    "        if new_ch == 2:\n",
    "            res_aud = np.stack([aud, aud])\n",
    "            return res_aud, sr\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported number of channels: {new_ch}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _pad_or_truncate(\n",
    "        aud_sr: tuple[np.ndarray, float], target_duration: float\n",
    "    ) -> tuple[np.ndarray, float]:\n",
    "        aud, sr = aud_sr\n",
    "\n",
    "        target_samples = int(sr * target_duration)\n",
    "        current_samples = aud.shape[-1] if aud.ndim > 1 else len(aud)\n",
    "\n",
    "        if current_samples > target_samples:\n",
    "            if aud.ndim > 1:\n",
    "                return aud[:, :target_samples], sr\n",
    "            else:\n",
    "                return aud[:target_samples], sr\n",
    "        elif current_samples < target_samples:\n",
    "            pad_samples = target_samples - current_samples\n",
    "            if aud.ndim > 1:\n",
    "                pad_width = ((0, 0), (0, pad_samples))\n",
    "            else:\n",
    "                pad_width = (0, pad_samples)\n",
    "            return np.pad(aud, pad_width, mode=\"constant\", constant_values=0), sr\n",
    "        else:\n",
    "            return aud, sr\n",
    "\n",
    "    def _get_cache_path(self, audio_path: Path) -> Path:\n",
    "        \"\"\"Generate cache path from file path\"\"\"\n",
    "        params_hash = f\"{self.n_fft}_{self.hop_length}_{self.n_mels}_{self.new_sr}_{self.new_ch}_{self.target_duration}\"\n",
    "        return self.cache_dir / f\"{audio_path.stem}_{params_hash}.npz\"\n",
    "\n",
    "    def _load_spectr(\n",
    "        self,\n",
    "        audio_dict: dict,\n",
    "        n_fft: int = 2048,\n",
    "        hop_length: int = 512,\n",
    "        n_mels: int = 40,\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Takes dict with keys: audio, sr, path, source_type\n",
    "        Returns dict with: mel_spectrogram, stft_spectrogram, audio, sr, path\n",
    "        \"\"\"\n",
    "\n",
    "        audio = audio_dict[\"audio\"]\n",
    "        sr = audio_dict[\"sr\"]\n",
    "        audio_path = audio_dict[\"path\"]\n",
    "        source_type = audio_dict[\"source_type\"]\n",
    "\n",
    "        # Try to load from cache (only for real file paths)\n",
    "        if self.save_cache and source_type == \"path\":\n",
    "            cache_path = self._get_cache_path(audio_path)\n",
    "            if cache_path.exists():\n",
    "                try:\n",
    "                    cached = np.load(cache_path)\n",
    "                    return {\n",
    "                        \"mel_spectrogram\": cached[\"mel_spectrogram\"],\n",
    "                        \"stft_spectrogram\": cached[\"stft_spectrogram\"],\n",
    "                        \"audio\": cached[\"audio\"],\n",
    "                        \"sr\": float(cached[\"sr\"]),\n",
    "                        \"path\": audio_path,\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    # If cache is corrupted, recompute\n",
    "                    pass\n",
    "\n",
    "        try:\n",
    "            aud_sr = (audio, sr)\n",
    "            aud_sr = self._pad_or_truncate(\n",
    "                aud_sr=aud_sr, target_duration=self.target_duration\n",
    "            )\n",
    "            aud_sr = self._rechannel(aud_sr=aud_sr, new_ch=self.new_ch)\n",
    "            aud_sr = self._resample(aud_sr=aud_sr, new_sr=self.new_sr)\n",
    "            aud, sr = aud_sr\n",
    "\n",
    "            # Compute STFT for features that need it\n",
    "            stft = librosa.stft(aud, n_fft=n_fft, hop_length=hop_length)\n",
    "            stft_mag = np.abs(stft)\n",
    "\n",
    "            # Compute mel spectrogram\n",
    "            mel_spect = librosa.feature.melspectrogram(\n",
    "                y=aud, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels\n",
    "            )\n",
    "            mel_spect_db = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "\n",
    "            # Save to cache only for real file paths\n",
    "            if self.save_cache and source_type == \"path\":\n",
    "                cache_path = self._get_cache_path(audio_path)\n",
    "                np.savez_compressed(\n",
    "                    cache_path,\n",
    "                    mel_spectrogram=mel_spect_db,\n",
    "                    stft_spectrogram=stft_mag,\n",
    "                    audio=aud,\n",
    "                    sr=sr,\n",
    "                )\n",
    "\n",
    "            return {\n",
    "                \"mel_spectrogram\": mel_spect_db,\n",
    "                \"stft_spectrogram\": stft_mag,\n",
    "                \"audio\": aud,\n",
    "                \"sr\": sr,\n",
    "                \"path\": audio_path,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error processing audio from {audio_path}: {e}\")\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X) -> np.ndarray:\n",
    "        \"\"\"X is now array of dicts from AudioLoader\"\"\"\n",
    "        results = []\n",
    "        for audio_dict in tqdm(X, desc=\"Computing spectrograms\"):\n",
    "            result = self._load_spectr(\n",
    "                audio_dict,\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.hop_length,\n",
    "                n_mels=self.n_mels,\n",
    "            )\n",
    "            results.append(result)\n",
    "        return np.array(results, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f073a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>album_title</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>['Kurt Vile']</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008-03-04</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.916</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.162</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>111.563</td>\n",
       "      <td>161173</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237</td>\n",
       "      <td>Garbage and (Garbage and Fire)</td>\n",
       "      <td>Barnacled</td>\n",
       "      <td>6</td>\n",
       "      <td>Garbage and (garbage On Fire)</td>\n",
       "      <td>['Barnacled']</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.640</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.799</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>140.368</td>\n",
       "      <td>449467</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238</td>\n",
       "      <td>France Attacks</td>\n",
       "      <td>Barnacled</td>\n",
       "      <td>6</td>\n",
       "      <td>France Attacks</td>\n",
       "      <td>['Barnacled']</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.411</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>56.929</td>\n",
       "      <td>820707</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>Machines and Muscles</td>\n",
       "      <td>CAVE</td>\n",
       "      <td>Butthash</td>\n",
       "      <td>Machines and Muscles</td>\n",
       "      <td>['Cave']</td>\n",
       "      <td>Psychic Psummer</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009-05-26</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.918</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>108.305</td>\n",
       "      <td>236960</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459</td>\n",
       "      <td>Machines and Muscles</td>\n",
       "      <td>CAVE</td>\n",
       "      <td>Butthash</td>\n",
       "      <td>Machines and Muscles</td>\n",
       "      <td>['Cave']</td>\n",
       "      <td>Release</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-10-21</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>93.887</td>\n",
       "      <td>303680</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id                     track_title artist_name        album_title  \\\n",
       "0        10                         Freeway   Kurt Vile  Constant Hitmaker   \n",
       "1       237  Garbage and (Garbage and Fire)   Barnacled                  6   \n",
       "2       238                  France Attacks   Barnacled                  6   \n",
       "3       459            Machines and Muscles        CAVE           Butthash   \n",
       "4       459            Machines and Muscles        CAVE           Butthash   \n",
       "\n",
       "                            name        artists              album  year  \\\n",
       "0                        Freeway  ['Kurt Vile']  Constant Hitmaker  2008   \n",
       "1  Garbage and (garbage On Fire)  ['Barnacled']                  6  2003   \n",
       "2                 France Attacks  ['Barnacled']                  6  2003   \n",
       "3           Machines and Muscles       ['Cave']    Psychic Psummer  2009   \n",
       "4           Machines and Muscles       ['Cave']            Release  2014   \n",
       "\n",
       "  release_date  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "0   2008-03-04         0.606   0.916    6    -8.162     1       0.0371   \n",
       "1   2003-01-01         0.280   0.640   11    -7.799     0       0.1230   \n",
       "2   2003-01-01         0.192   0.411    2    -9.445     1       0.0655   \n",
       "3   2009-05-26         0.584   0.918    7    -9.883     1       0.0345   \n",
       "4   2014-10-21         0.415   0.646    2   -12.022     1       0.0399   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "0        0.1400             0.356    0.1320   0.8890  111.563       161173   \n",
       "1        0.3490             0.675    0.1360   0.0537  140.368       449467   \n",
       "2        0.5390             0.709    0.0909   0.1390   56.929       820707   \n",
       "3        0.0254             0.770    0.3480   0.1140  108.305       236960   \n",
       "4        0.0189             0.948    0.0965   0.1230   93.887       303680   \n",
       "\n",
       "   time_signature  \n",
       "0             4.0  \n",
       "1             4.0  \n",
       "2             4.0  \n",
       "3             5.0  \n",
       "4             5.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data = pd.read_csv(prc / \"matched_metadata.csv\")\n",
    "audio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30600826",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 80, 100, 120, 140, 170, float(\"inf\")]\n",
    "numeric_labels = [0, 1, 2, 3, 4, 5]  # Now 6 labels for 6 bins\n",
    "\n",
    "audio_data[\"tempo_bins\"] = pd.cut(\n",
    "    audio_data[\"tempo\"], bins=bins, labels=numeric_labels, right=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc510ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = audio_data[\"track_id\"].map(lambda id: asp / f\"{str(id).zfill(6)}.mp3\")\n",
    "y = audio_data[\n",
    "    [\n",
    "        \"danceability\",\n",
    "        \"energy\",\n",
    "        \"key\",\n",
    "        \"loudness\",\n",
    "        \"mode\",\n",
    "        \"speechiness\",\n",
    "        \"acousticness\",\n",
    "        \"instrumentalness\",\n",
    "        \"liveness\",\n",
    "        \"valence\",\n",
    "        \"tempo_bins\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59f6a92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.606</td>\n",
       "      <td>0.916</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.162</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.280</td>\n",
       "      <td>0.640</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.799</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.192</td>\n",
       "      <td>0.411</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.584</td>\n",
       "      <td>0.918</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.415</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.606   0.916    6    -8.162     1       0.0371        0.1400   \n",
       "1         0.280   0.640   11    -7.799     0       0.1230        0.3490   \n",
       "2         0.192   0.411    2    -9.445     1       0.0655        0.5390   \n",
       "3         0.584   0.918    7    -9.883     1       0.0345        0.0254   \n",
       "4         0.415   0.646    2   -12.022     1       0.0399        0.0189   \n",
       "\n",
       "   instrumentalness  liveness  valence tempo_bins  \n",
       "0             0.356    0.1320   0.8890          2  \n",
       "1             0.675    0.1360   0.0537          4  \n",
       "2             0.709    0.0909   0.1390          0  \n",
       "3             0.770    0.3480   0.1140          2  \n",
       "4             0.948    0.0965   0.1230          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e947936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0\n"
     ]
    }
   ],
   "source": [
    "print(y[\"tempo_bins\"].max(), y[\"tempo_bins\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bdf169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:1383, X_test: 346, y_train: 1383, y_test: 346\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\n",
    "    f\"X_train:{len(X_train)}, X_test: {len(X_test)}, y_train: {len(y_train)}, y_test: {len(y_test)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18bb316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sr: float = 22050,\n",
    "        hop_length: int = 512,\n",
    "        n_fft: int = 2048,\n",
    "        n_mfcc: int = 13,\n",
    "        n_chroma: int = 12,\n",
    "        f0_min: float = 65.41,\n",
    "        f0_max: float = 2093.0,\n",
    "        enable_cache: bool = True,\n",
    "        cache_path: Path = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.sr = sr\n",
    "        self.hop_length = hop_length\n",
    "        self.n_fft = n_fft\n",
    "        self.n_chroma = n_chroma\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.f0_min = f0_min\n",
    "        self.f0_max = f0_max\n",
    "        self.enable_cache = enable_cache\n",
    "        self.cache_path = cache_path\n",
    "        if self.enable_cache and cache_path:\n",
    "            self.cache_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _get_cache_key(self, audio_path: Path, source_type: str) -> str | None:\n",
    "        \"\"\"Generate cache key from path\"\"\"\n",
    "        if source_type != \"path\":\n",
    "            return None  # Don't cache uploaded files\n",
    "\n",
    "        params_str = f\"{audio_path}_{self.sr}_{self.hop_length}_{self.n_fft}_{self.n_chroma}_{self.n_mfcc}_{self.f0_min}_{self.f0_max}\"\n",
    "        return hashlib.md5(params_str.encode()).hexdigest()\n",
    "\n",
    "    def _get_cache_file(self, cache_key: str) -> Path:\n",
    "        return self.cache_path / f\"{cache_key}.pkl\"\n",
    "\n",
    "    def _load_from_cache(self, cache_key: str):\n",
    "        if cache_key is None:\n",
    "            return None\n",
    "\n",
    "        cache_file = self._get_cache_file(cache_key)\n",
    "        if cache_file.exists():\n",
    "            try:\n",
    "                with open(cache_file, \"rb\") as f:\n",
    "                    return pickle.load(f)\n",
    "            except:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    def _save_to_cache(self, cache_key: str, stats: dict):\n",
    "        \"\"\"Save features to cache\"\"\"\n",
    "        if cache_key is None:\n",
    "            return\n",
    "\n",
    "        cache_file = self._get_cache_file(cache_key)\n",
    "        try:\n",
    "            with open(cache_file, \"wb\") as f:\n",
    "                pickle.dump(stats, f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    @staticmethod\n",
    "    def make_stats(feature_array, features_name):\n",
    "        return {\n",
    "            f\"{features_name}_mean\": np.mean(feature_array),\n",
    "            f\"{features_name}_std\": np.std(feature_array),\n",
    "            f\"{features_name}_min\": np.min(feature_array),\n",
    "            f\"{features_name}_max\": np.max(feature_array),\n",
    "            f\"{features_name}_median\": np.median(feature_array),\n",
    "            f\"{features_name}_q25\": np.percentile(feature_array, 25),\n",
    "            f\"{features_name}_q75\": np.percentile(feature_array, 75),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def temporal_extract(\n",
    "        audio: np.ndarray, stft_spectrogram: np.ndarray, sr: float, hop_length: int\n",
    "    ):\n",
    "        # Use STFT spectrogram for RMS\n",
    "        rms = librosa.feature.rms(S=stft_spectrogram, hop_length=hop_length)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=audio, hop_length=hop_length)\n",
    "\n",
    "        envelope = rms[0]\n",
    "        temporal_features = {}\n",
    "\n",
    "        if len(envelope) > 0 and np.max(envelope) > 0:\n",
    "            envelope_norm = envelope / np.max(envelope)\n",
    "\n",
    "            # Attack time (time to reach 90% of max amplitude)\n",
    "            attack_threshold = 0.9\n",
    "            attack_frame = np.argmax(envelope_norm >= attack_threshold)\n",
    "            temporal_features[\"attack_time\"] = (attack_frame * hop_length) / sr\n",
    "\n",
    "            # Temporal centroid (center of mass in time)\n",
    "            times = np.arange(len(envelope_norm)) * hop_length / sr\n",
    "            temporal_features[\"temporal_centroid\"] = np.sum(times * envelope_norm) / (\n",
    "                np.sum(envelope_norm) + 1e-8\n",
    "            )\n",
    "        else:\n",
    "            temporal_features[\"attack_time\"] = 0.0\n",
    "            temporal_features[\"temporal_centroid\"] = 0.0\n",
    "\n",
    "        frame_features = {\n",
    "            \"zcr\": zcr.flatten(),\n",
    "            \"rms\": rms.flatten(),\n",
    "        }\n",
    "\n",
    "        frame_features.update(temporal_features)\n",
    "        return frame_features\n",
    "\n",
    "    @staticmethod\n",
    "    def spectral_extract(\n",
    "        audio: np.ndarray,\n",
    "        stft_spectrogram: np.ndarray,\n",
    "        sr: float,\n",
    "        hop_length: int,\n",
    "        n_mfcc: int,\n",
    "    ):\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(\n",
    "            S=stft_spectrogram, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(\n",
    "            S=stft_spectrogram, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(\n",
    "            S=stft_spectrogram, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(\n",
    "            S=stft_spectrogram, hop_length=hop_length\n",
    "        )\n",
    "        spectral_flux = librosa.onset.onset_strength(S=stft_spectrogram, sr=sr)\n",
    "\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            S=librosa.power_to_db(stft_spectrogram**2),\n",
    "            sr=sr,\n",
    "            n_mfcc=n_mfcc,\n",
    "            hop_length=hop_length,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"spectral_centroid\": spectral_centroid.flatten(),\n",
    "            \"spectral_bandwidth\": spectral_bandwidth.flatten(),\n",
    "            \"spectral_rolloff\": spectral_rolloff.flatten(),\n",
    "            \"spectral_flatness\": spectral_flatness.flatten(),\n",
    "            \"spectral_flux\": spectral_flux,\n",
    "            \"mfccs\": mfccs,  # Shape: (13, n_frames)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_rhythm_features(audio: np.ndarray, sr: float):\n",
    "        tempo, beats = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "\n",
    "        # Compute beat strength only if beats detected\n",
    "        beat_strength = np.mean(onset_env[beats]) if len(beats) > 0 else 0.0\n",
    "        onset_rate = len(beats) / (len(audio) / sr) if len(audio) > 0 else 0.0\n",
    "        if isinstance(tempo, np.ndarray):\n",
    "            tempo = float(np.median(tempo))\n",
    "        else:\n",
    "            tempo = float(tempo)\n",
    "        return {\n",
    "            \"tempo\": tempo,  # Scalar\n",
    "            \"beat_strength\": beat_strength,  # Scalar\n",
    "            \"onset_rate\": onset_rate,  # Scalar\n",
    "            \"onset_strength\": onset_env,  # Time series\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_chroma_features(\n",
    "        audio: np.ndarray, sr: float, hop_length: int, n_chroma: int\n",
    "    ):\n",
    "        chroma = librosa.feature.chroma_stft(\n",
    "            y=audio, sr=sr, hop_length=hop_length, n_chroma=n_chroma\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"chroma\": chroma,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_hpss_features(audio: np.ndarray):\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(audio)\n",
    "\n",
    "        h_energy = np.mean(y_harmonic**2)\n",
    "        p_energy = np.mean(y_percussive**2)\n",
    "\n",
    "        return {\n",
    "            \"harmonic_percussive_ratio\": h_energy / (p_energy + 1e-8),  # Scalar\n",
    "            \"harmonic_energy\": h_energy,  # Scalar\n",
    "            \"percussive_energy\": p_energy,  # Scalar\n",
    "        }, y_harmonic  # Return harmonic component for further analysis\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_harmonic_features(\n",
    "        y_harmonic, sr, hop_length=512, n_fft=2048, f0_min=65.41, f0_max=2093.0\n",
    "    ):\n",
    "        features = {}\n",
    "\n",
    "        # Get fundamental frequency estimates\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "            y_harmonic,\n",
    "            fmin=f0_min,\n",
    "            fmax=f0_max,\n",
    "            sr=sr,\n",
    "            hop_length=hop_length,\n",
    "        )\n",
    "\n",
    "        # Compute STFT\n",
    "        stft = librosa.stft(y_harmonic, n_fft=n_fft, hop_length=hop_length)\n",
    "        mag_spec = np.abs(stft)\n",
    "        freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "\n",
    "        # Use only voiced frames\n",
    "        valid_indices = np.where(voiced_flag)[0]\n",
    "        valid_f0 = f0[voiced_flag]\n",
    "\n",
    "        if len(valid_f0) > 0:\n",
    "            inharmonicity_values = []\n",
    "            t1_values = []\n",
    "            t2_values = []\n",
    "            t3_values = []\n",
    "\n",
    "            for idx, f0_val in zip(valid_indices, valid_f0):\n",
    "                if np.isnan(f0_val) or f0_val <= 0:\n",
    "                    continue\n",
    "\n",
    "                frame_spec = mag_spec[:, idx]\n",
    "\n",
    "                # --- INHARMONICITY CALCULATION ---\n",
    "                peaks, properties = find_peaks(\n",
    "                    frame_spec, height=np.max(frame_spec) * 0.1\n",
    "                )\n",
    "                peak_freqs = freqs[peaks]\n",
    "                peak_mags = properties[\"peak_heights\"]\n",
    "\n",
    "                if len(peak_freqs) > 0:\n",
    "                    sorted_idx = np.argsort(peak_mags)[::-1]\n",
    "                    peak_freqs = peak_freqs[sorted_idx[:10]]\n",
    "                    peak_mags = peak_mags[sorted_idx[:10]]\n",
    "\n",
    "                    deviations = []\n",
    "                    for n in range(1, min(8, len(peak_freqs) + 1)):\n",
    "                        expected_freq = f0_val * n\n",
    "                        if expected_freq < freqs[-1]:\n",
    "                            closest_idx = np.argmin(np.abs(peak_freqs - expected_freq))\n",
    "                            deviation = (\n",
    "                                np.abs(peak_freqs[closest_idx] - expected_freq)\n",
    "                                / expected_freq\n",
    "                            )\n",
    "                            deviations.append(deviation)\n",
    "\n",
    "                    if deviations:\n",
    "                        inharmonicity_values.append(np.mean(deviations))\n",
    "\n",
    "                # --- TRISTIMULUS CALCULATION ---\n",
    "                harmonic_energies = []\n",
    "                for n in range(1, 11):\n",
    "                    harmonic_freq = f0_val * n\n",
    "                    if harmonic_freq >= freqs[-1]:\n",
    "                        break\n",
    "\n",
    "                    bin_idx = np.argmin(np.abs(freqs - harmonic_freq))\n",
    "                    start_bin = max(0, bin_idx - 3)\n",
    "                    end_bin = min(len(frame_spec), bin_idx + 4)\n",
    "                    energy = np.sum(frame_spec[start_bin:end_bin])\n",
    "                    harmonic_energies.append(energy)\n",
    "\n",
    "                if len(harmonic_energies) >= 5:\n",
    "                    total_energy = np.sum(harmonic_energies) + 1e-8\n",
    "\n",
    "                    t1 = harmonic_energies[0] / total_energy\n",
    "                    t2 = np.sum(harmonic_energies[1:4]) / total_energy\n",
    "                    t3 = np.sum(harmonic_energies[4:]) / total_energy\n",
    "\n",
    "                    t1_values.append(t1)\n",
    "                    t2_values.append(t2)\n",
    "                    t3_values.append(t3)\n",
    "\n",
    "            # Aggregate features\n",
    "            features[\"inharmonicity\"] = (\n",
    "                np.mean(inharmonicity_values) if inharmonicity_values else 0.0\n",
    "            )\n",
    "            features[\"tristimulus_1\"] = np.mean(t1_values) if t1_values else 0.0\n",
    "            features[\"tristimulus_2\"] = np.mean(t2_values) if t2_values else 0.0\n",
    "            features[\"tristimulus_3\"] = np.mean(t3_values) if t3_values else 0.0\n",
    "            features[\"f0_mean\"] = np.mean(valid_f0)\n",
    "            features[\"f0_std\"] = np.std(valid_f0)\n",
    "            features[\"voiced_ratio\"] = np.sum(voiced_flag) / len(voiced_flag)\n",
    "        else:\n",
    "            # No voiced frames\n",
    "            features[\"inharmonicity\"] = 0.0\n",
    "            features[\"tristimulus_1\"] = 0.0\n",
    "            features[\"tristimulus_2\"] = 0.0\n",
    "            features[\"tristimulus_3\"] = 0.0\n",
    "            features[\"f0_mean\"] = 0.0\n",
    "            features[\"f0_std\"] = 0.0\n",
    "            features[\"voiced_ratio\"] = 0.0\n",
    "\n",
    "        return features\n",
    "\n",
    "    def extract_all_features(self, audio: np.ndarray, stft_spectrogram: np.ndarray):\n",
    "        all_features = {}\n",
    "\n",
    "        all_features.update(\n",
    "            self.temporal_extract(audio, stft_spectrogram, self.sr, self.hop_length)\n",
    "        )\n",
    "\n",
    "        all_features.update(\n",
    "            self.spectral_extract(\n",
    "                audio, stft_spectrogram, self.sr, self.hop_length, self.n_mfcc\n",
    "            )  # ← Pass n_mfcc\n",
    "        )\n",
    "\n",
    "        all_features.update(self.extract_rhythm_features(audio, self.sr))\n",
    "\n",
    "        all_features.update(\n",
    "            self.extract_chroma_features(audio, self.sr, self.hop_length, self.n_chroma)\n",
    "        )\n",
    "\n",
    "        hpss_features, y_harmonic = self.extract_hpss_features(audio)\n",
    "        all_features.update(hpss_features)\n",
    "\n",
    "        all_features.update(\n",
    "            self.extract_harmonic_features(\n",
    "                y_harmonic,\n",
    "                self.sr,\n",
    "                self.hop_length,\n",
    "                self.n_fft,\n",
    "                self.f0_min,\n",
    "                self.f0_max,\n",
    "            )  # ← Pass all params\n",
    "        )\n",
    "\n",
    "        return all_features\n",
    "\n",
    "    def compute_statistics(self, features: Dict[str, Any]) -> Dict[str, float]:\n",
    "        \"\"\"Convert all features to statistics (scalars)\"\"\"\n",
    "        stats = {}\n",
    "\n",
    "        for key, val in features.items():\n",
    "            # Handle different feature types\n",
    "            if isinstance(val, (int, float, np.integer, np.floating)):\n",
    "                # Already a scalar (tempo, attack_time, etc.)\n",
    "                stats[key] = float(val)\n",
    "\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                if val.ndim == 1:\n",
    "                    # 1D time series (RMS, spectral_centroid, etc.)\n",
    "                    stats.update(self.make_stats(val, key))\n",
    "\n",
    "                elif val.ndim == 2:\n",
    "                    # 2D features (MFCCs, chroma)\n",
    "                    if key == \"mfccs\":\n",
    "                        # MFCCs: shape (13, n_frames)\n",
    "                        for i in range(val.shape[0]):  # Iterate over 13 coefficients\n",
    "                            mfcc_i = val[i, :]\n",
    "                            stats.update(self.make_stats(mfcc_i, f\"mfcc_{i}\"))\n",
    "\n",
    "                    elif key == \"chroma\":\n",
    "                        # Chroma: shape (12, n_frames)\n",
    "                        for i in range(val.shape[0]):  # Iterate over 12 pitch classes\n",
    "                            chroma_i = val[i, :]\n",
    "                            stats.update(self.make_stats(chroma_i, f\"chroma_{i}\"))\n",
    "\n",
    "                    else:\n",
    "                        # Generic 2D handling\n",
    "                        for i in range(val.shape[0]):\n",
    "                            stats.update(self.make_stats(val[i, :], f\"{key}_{i}\"))\n",
    "\n",
    "        return stats\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"X is array of dicts from SpectrogramExtractor\"\"\"\n",
    "        feature_vectors = []\n",
    "\n",
    "        for item in tqdm(X, desc=\"Extracting features\"):\n",
    "            audio = item[\"audio\"]\n",
    "            stft_spectrogram = item[\"stft_spectrogram\"]\n",
    "            audio_path = item.get(\"path\")\n",
    "\n",
    "            # Determine source type from path\n",
    "            source_type = (\n",
    "                \"path\"\n",
    "                if (audio_path and not str(audio_path).startswith(\"uploaded_\"))\n",
    "                else \"bytes\"\n",
    "            )\n",
    "\n",
    "            stats = None\n",
    "\n",
    "            # Try cache only for real files\n",
    "            if self.enable_cache and self.cache_path:\n",
    "                cache_key = self._get_cache_key(audio_path, source_type)\n",
    "                stats = self._load_from_cache(cache_key)\n",
    "\n",
    "            if stats is None:\n",
    "                features = self.extract_all_features(audio, stft_spectrogram)\n",
    "                stats = self.compute_statistics(features)\n",
    "\n",
    "                # Save to cache only for real files\n",
    "                if self.enable_cache and self.cache_path:\n",
    "                    cache_key = self._get_cache_key(audio_path, source_type)\n",
    "                    self._save_to_cache(cache_key, stats)\n",
    "\n",
    "            feature_vectors.append(stats)\n",
    "\n",
    "        return pd.DataFrame(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc10faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic usage - extract features and train a model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Extraction pipeline\n",
    "extraction_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"audio_loader\", AudioLoader(sr=22050)),\n",
    "        (\n",
    "            \"spectrogram\",\n",
    "            SpectrogramExtractor(\n",
    "                new_sr=22050, save_cache=True, cache_dir=intr / \"spectrogram_cache\"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"features\",\n",
    "            StatsFeatureExtractor(\n",
    "                sr=22050, enable_cache=True, cache_path=intr / \"stats_feat\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13a0267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audio: 100%|██████████| 1383/1383 [00:54<00:00, 25.36it/s]\n",
      "Computing spectrograms: 100%|██████████| 1383/1383 [00:52<00:00, 26.39it/s]\n",
      "Extracting features: 100%|██████████| 1383/1383 [00:00<00:00, 4897.35it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_extracted = extraction_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4030cfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audio: 100%|██████████| 346/346 [00:13<00:00, 24.85it/s]\n",
      "Computing spectrograms: 100%|██████████| 346/346 [00:12<00:00, 27.99it/s]\n",
      "Extracting features: 100%|██████████| 346/346 [00:00<00:00, 4692.62it/s]\n",
      "/home/moad/desktop/music-recommender/.venv/lib/python3.11/site-packages/sklearn/pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_test_extracted = extraction_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2741f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1383 entries, 0 to 1382\n",
      "Columns: 246 entries, zcr_mean to voiced_ratio\n",
      "dtypes: float32(203), float64(43)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_extracted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5e20691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_extracted.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e85abb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After variance filter: 120 features\n",
      "After correlation filter: 69 features\n",
      "After SelectKBest: 69 features\n",
      "X_train_reduced shape: (1383, 69)\n",
      "X_test_reduced shape: (346, 69)\n"
     ]
    }
   ],
   "source": [
    "def multi_output_mutual_info(X, y):\n",
    "    if len(y.shape) == 1:\n",
    "        return mutual_info_regression(X, y)\n",
    "\n",
    "    mi_scores = np.zeros(X.shape[1])\n",
    "    for i in range(y.shape[1]):\n",
    "        mi_scores += mutual_info_regression(X, y[:, i])\n",
    "\n",
    "    return mi_scores / y.shape[1]\n",
    "\n",
    "\n",
    "class ReduceNumFeature(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=150, variance_thershold=0.95) -> None:\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.variance_filter = None\n",
    "        self.correlation_columns_to_drop = None\n",
    "        self.selector = None\n",
    "        self.variance_thershold = variance_thershold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.variance_filter = VarianceThreshold(threshold=self.variance_thershold)\n",
    "        X_filt_var = self.variance_filter.fit_transform(X)\n",
    "        print(f\"After variance filter: {X_filt_var.shape[1]} features\")\n",
    "\n",
    "        X_filt_var_df = pd.DataFrame(X_filt_var)\n",
    "        correlation_matrix = X_filt_var_df.corr().abs()\n",
    "\n",
    "        upper = correlation_matrix.where(\n",
    "            np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    "        )\n",
    "        self.correlation_columns_to_drop = [\n",
    "            column for column in upper.columns if any(upper[column] > 0.95)\n",
    "        ]\n",
    "\n",
    "        X_filt_uncorr = X_filt_var_df.drop(\n",
    "            columns=self.correlation_columns_to_drop\n",
    "        ).values\n",
    "        print(f\"After correlation filter: {X_filt_uncorr.shape[1]} features\")\n",
    "\n",
    "        if y is not None:\n",
    "            k_actual = min(self.k, X_filt_uncorr.shape[1])\n",
    "            self.selector = SelectKBest(multi_output_mutual_info, k=k_actual)\n",
    "            self.selector.fit(X_filt_uncorr, y)\n",
    "            print(\n",
    "                f\"After SelectKBest: {self.selector.transform(X_filt_uncorr).shape[1]} features\"\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_filt_var = self.variance_filter.transform(X)\n",
    "\n",
    "        X_filt_var_df = pd.DataFrame(X_filt_var)\n",
    "        X_filt_uncorr = X_filt_var_df.drop(\n",
    "            columns=self.correlation_columns_to_drop\n",
    "        ).values\n",
    "\n",
    "        if self.selector is not None:\n",
    "            X_filt_selected = self.selector.transform(X_filt_uncorr)\n",
    "        else:\n",
    "            X_filt_selected = X_filt_uncorr\n",
    "\n",
    "        return X_filt_selected\n",
    "\n",
    "\n",
    "reducer = ReduceNumFeature(k=75)\n",
    "reducer.fit(X_train_extracted, y_train)\n",
    "X_train_reduced = reducer.transform(X_train_extracted)\n",
    "X_test_reduced = reducer.transform(X_test_extracted)\n",
    "print(f\"X_train_reduced shape: {X_train_reduced.shape}\")\n",
    "print(f\"X_test_reduced shape: {X_test_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8263701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA reduced to 4 components\n",
      "Explained variance: 0.959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_extracted)\n",
    "X_test_pca = pca.transform(X_test_extracted)\n",
    "\n",
    "print(f\"PCA reduced to {X_train_pca.shape[1]} components\")\n",
    "print(f\"Explained variance: {pca.explained_variance_ratio_.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8dabe6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1383, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e83fa286",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORING_METRICS = {\n",
    "    \"regression\": {\n",
    "        \"r2\": \"r2\",\n",
    "        \"neg_mae\": \"neg_mean_absolute_error\",\n",
    "        \"neg_rmse\": \"neg_root_mean_squared_error\",\n",
    "        \"neg_mape\": \"neg_mean_absolute_percentage_error\",\n",
    "        \"explained_variance\": \"explained_variance\",\n",
    "    },\n",
    "    \"classification\": {\n",
    "        \"accuracy\": \"accuracy\",\n",
    "        \"f1_macro\": \"f1_macro\",\n",
    "        \"f1_weighted\": \"f1_weighted\",\n",
    "        \"precision_macro\": \"precision_macro\",\n",
    "        \"recall_macro\": \"recall_macro\",\n",
    "        \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf43f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.DataFrame(y_train, columns=y.columns)\n",
    "y_test_df = pd.DataFrame(y_test, columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09541289",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_groups = {\n",
    "    \"regression\": {\n",
    "        \"energy_mood\": [\"energy\", \"valence\", \"danceability\"],\n",
    "        \"production\": [\"loudness\", \"acousticness\", \"instrumentalness\", \"liveness\"],\n",
    "        \"structure\": [\"speechiness\"],\n",
    "    },\n",
    "\"classification\": {\n",
    "    \"key\": [\"key\"],\n",
    "    \"mode\": [\"mode\"], \n",
    "    \"tempo_bins\": [\"tempo_bins\"]\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c51b2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = {\n",
    "    \"regression\": {\n",
    "        \"Ridge\": {\n",
    "            \"base_model\": Ridge(),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__alpha\": Real(0.1, 10.0, prior=\"log-uniform\"),\n",
    "                \"estimator__solver\": Categorical([\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]),\n",
    "            },\n",
    "        },\n",
    "        \"Lasso\": {\n",
    "            \"base_model\": Lasso(),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__alpha\": Real(0.0001, 1.0, prior=\"log-uniform\"),\n",
    "                \"estimator__selection\": Categorical([\"cyclic\", \"random\"]),\n",
    "            },\n",
    "        },\n",
    "        \"ElasticNet\": {\n",
    "            \"base_model\": ElasticNet(),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__alpha\": Real(0.0001, 1.0, prior=\"log-uniform\"),\n",
    "                \"estimator__l1_ratio\": Real(0.1, 1.0),\n",
    "                \"estimator__selection\": Categorical([\"cyclic\", \"random\"]),\n",
    "            },\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            \"base_model\": RandomForestRegressor(random_state=42),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__n_estimators\": Integer(150, 350),  # Extended from 100-300\n",
    "                \"estimator__max_depth\": Integer(10, 20),\n",
    "                \"estimator__min_samples_split\": Integer(2, 8),\n",
    "                \"estimator__min_samples_leaf\": Integer(3, 8),\n",
    "                \"estimator__max_features\": Categorical([\"sqrt\", \"log2\", None]),\n",
    "            },\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"base_model\": XGBRegressor(random_state=42),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__n_estimators\": Integer(200, 700),  # Extended from 200-600\n",
    "                \"estimator__max_depth\": Integer(8, 15),\n",
    "                \"estimator__learning_rate\": Real(0.01, 0.05, prior=\"log-uniform\"),\n",
    "                \"estimator__subsample\": Real(0.6, 1.0),\n",
    "                \"estimator__colsample_bytree\": Real(0.6, 1.0),\n",
    "                \"estimator__gamma\": Real(0, 1.0),\n",
    "            },\n",
    "        },\n",
    "        \"SVM\": {\n",
    "            \"base_model\": SVR(kernel=\"rbf\"),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__C\": Real(0.1, 100.0, prior=\"log-uniform\"),\n",
    "                \"estimator__gamma\": Real(0.00001, 0.01, prior=\"log-uniform\"),\n",
    "                \"estimator__epsilon\": Real(0.01, 0.2),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"classification\": {\n",
    "        \"Random Forest\": {\n",
    "            \"base_model\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__n_estimators\": Integer(150, 350),  # Extended from 150-300\n",
    "                \"estimator__max_depth\": Integer(8, 20),\n",
    "                \"estimator__min_samples_split\": Integer(2, 10),\n",
    "                \"estimator__min_samples_leaf\": Integer(3, 6),\n",
    "                \"estimator__max_features\": Categorical([\"sqrt\", \"log2\", None]),\n",
    "                \"estimator__bootstrap\": Categorical([True, False]),\n",
    "            },\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"base_model\": XGBClassifier(random_state=42),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__n_estimators\": Integer(300, 700),  # Keep as is (was already extended)\n",
    "                \"estimator__max_depth\": Integer(8, 15),\n",
    "                \"estimator__learning_rate\": Real(0.01, 0.3, prior=\"log-uniform\"),\n",
    "                \"estimator__subsample\": Real(0.6, 1.0),\n",
    "                \"estimator__colsample_bytree\": Real(0.8, 1.0),\n",
    "                \"estimator__gamma\": Real(0, 2.0),\n",
    "                \"estimator__reg_alpha\": Real(0, 10.0),  # Extended from 0-5\n",
    "                \"estimator__reg_lambda\": Real(0, 30.0),\n",
    "            },\n",
    "        },\n",
    "        \"SVM\": {\n",
    "            \"base_model\": SVC(kernel=\"rbf\", probability=True, random_state=42, class_weight='balanced'),\n",
    "            \"param_grid\": {\n",
    "                \"estimator__C\": Real(1.0, 20.0, prior=\"log-uniform\"),\n",
    "                \"estimator__gamma\": Real(0.001, 0.02, prior=\"log-uniform\"),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_config = {\n",
    "    \"Ridge\": 30,\n",
    "    \"Lasso\": 30,\n",
    "    \"ElasticNet\": 30,\n",
    "    \"Random Forest\": 50,  \n",
    "    \"XGBoost\": 50,\n",
    "    \"SVM\": 40,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge on regression - energy_mood...\n",
      "Training Lasso on regression - energy_mood...\n",
      "Training ElasticNet on regression - energy_mood...\n",
      "Training Random Forest on regression - energy_mood...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     56\u001b[39m     cv_strategy = \u001b[32m5\u001b[39m\n\u001b[32m     58\u001b[39m search = BayesSearchCV(\n\u001b[32m     59\u001b[39m     estimator=pipe,\n\u001b[32m     60\u001b[39m     search_spaces=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     67\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_extracted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m y_pred = search.predict(X_test_extracted)\n\u001b[32m     72\u001b[39m result = {\n\u001b[32m     73\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtask_type\u001b[39m\u001b[33m\"\u001b[39m: task_type,\n\u001b[32m     74\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgroup\u001b[39m\u001b[33m\"\u001b[39m: group_name,\n\u001b[32m     75\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model_name,\n\u001b[32m     76\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtargets\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(target_cols),\n\u001b[32m     77\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/skopt/searchcv.py:542\u001b[39m, in \u001b[36mBayesSearchCV.fit\u001b[39m\u001b[34m(self, X, y, groups, callback, **fit_params)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.refit):\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBayesSearchCV doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt support a callable refit, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt define an implicit score to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    539\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moptimize\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    540\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_train_score:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/skopt/searchcv.py:599\u001b[39m, in \u001b[36mBayesSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter > \u001b[32m0\u001b[39m:\n\u001b[32m    596\u001b[39m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[32m    597\u001b[39m     n_points_adjusted = \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     optim_result, score_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m     n_iter -= n_points\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/skopt/searchcv.py:453\u001b[39m, in \u001b[36mBayesSearchCV._step\u001b[39m\u001b[34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[32m    451\u001b[39m params_dict = [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m all_results = \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/desktop/music-recommender/.venv/lib/python3.11/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for task_type, models in model_test.items():\n",
    "    scoring_metrics = SCORING_METRICS[task_type]\n",
    "    groups = target_groups[task_type]\n",
    "    \n",
    "    for group_name, target_cols in groups.items():\n",
    "        y_train_group = y_train_df[target_cols].values\n",
    "        y_test_group = y_test_df[target_cols].values\n",
    "        \n",
    "        # Determine if we need multi-output wrapper\n",
    "        is_multi_output = len(target_cols) > 1\n",
    "        \n",
    "        for model_name, model_info in models.items():\n",
    "            print(f\"Training {model_name} on {task_type} - {group_name}...\")\n",
    "\n",
    "            base_model = model_info[\"base_model\"]\n",
    "            \n",
    "            if task_type == \"classification\" and model_name == \"XGBoost\" and not is_multi_output:\n",
    "                from sklearn.utils.class_weight import compute_class_weight\n",
    "                classes = np.unique(y_train_group.ravel())\n",
    "                if len(classes) == 2:\n",
    "                    class_weights = compute_class_weight('balanced', classes=classes, y=y_train_group.ravel())\n",
    "                    base_model.set_params(scale_pos_weight=class_weights[1]/class_weights[0])\n",
    "                \n",
    "            if is_multi_output:\n",
    "                if task_type == \"regression\":\n",
    "                    model = MultiOutputRegressor(base_model)\n",
    "                    param_grid = {\n",
    "                        k.replace(\"estimator__\", \"estimator__estimator__\"): v \n",
    "                        for k, v in model_info[\"param_grid\"].items()\n",
    "                    }\n",
    "                else:\n",
    "                    model = MultiOutputClassifier(base_model)\n",
    "                    param_grid = {\n",
    "                        k.replace(\"estimator__\", \"estimator__estimator__\"): v \n",
    "                        for k, v in model_info[\"param_grid\"].items()\n",
    "                    }\n",
    "            else:\n",
    "                model = base_model\n",
    "                param_grid = model_info[\"param_grid\"]\n",
    "                y_train_group = y_train_group.ravel()\n",
    "                y_test_group = y_test_group.ravel()\n",
    "\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"pca\", PCA(n_components=50)),\n",
    "                (\"estimator\", model)\n",
    "            ])\n",
    "            \n",
    "            refit_metric = \"r2\" if task_type == \"regression\" else \"f1_weighted\"\n",
    "            \n",
    "            if task_type == \"classification\":\n",
    "                from sklearn.model_selection import StratifiedKFold\n",
    "                cv_strategy = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "            else:\n",
    "                cv_strategy = 4\n",
    "            \n",
    "            search = BayesSearchCV(\n",
    "                estimator=pipe,\n",
    "                search_spaces=param_grid,\n",
    "                scoring=scoring_metrics,\n",
    "                refit=refit_metric,\n",
    "                cv=cv_strategy,\n",
    "                n_iter=n_iter_config[model_name],\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "            )\n",
    "\n",
    "            search.fit(X_train_extracted, y_train_group)\n",
    "            y_pred = search.predict(X_test_extracted)\n",
    "\n",
    "            result = {\n",
    "                \"task_type\": task_type,\n",
    "                \"group\": group_name,\n",
    "                \"model\": model_name,\n",
    "                \"targets\": \", \".join(target_cols),\n",
    "            }\n",
    "\n",
    "            if task_type == \"regression\":\n",
    "                if not is_multi_output:\n",
    "                    y_test_group = y_test_group.reshape(-1, 1)\n",
    "                    y_pred = y_pred.reshape(-1, 1)\n",
    "                \n",
    "                result[\"r2\"] = r2_score(y_test_group, y_pred)\n",
    "                result[\"neg_mae\"] = -mean_absolute_error(y_test_group, y_pred)\n",
    "                result[\"neg_rmse\"] = -np.sqrt(mean_squared_error(y_test_group, y_pred))\n",
    "                try:\n",
    "                    result[\"neg_mape\"] = -mean_absolute_percentage_error(y_test_group, y_pred)\n",
    "                except:\n",
    "                    result[\"neg_mape\"] = None\n",
    "                result[\"explained_variance\"] = explained_variance_score(y_test_group, y_pred)\n",
    "                for metric in SCORING_METRICS[\"classification\"].values():\n",
    "                    result[metric] = None\n",
    "            else:\n",
    "                result[\"accuracy\"] = accuracy_score(y_test_group, y_pred)\n",
    "                result[\"f1_macro\"] = f1_score(y_test_group, y_pred, average=\"macro\", zero_division=0)\n",
    "                result[\"f1_weighted\"] = f1_score(y_test_group, y_pred, average=\"weighted\", zero_division=0)\n",
    "                result[\"precision_macro\"] = precision_score(y_test_group, y_pred, average=\"macro\", zero_division=0)\n",
    "                result[\"recall_macro\"] = recall_score(y_test_group, y_pred, average=\"macro\", zero_division=0)\n",
    "                result[\"balanced_accuracy\"] = balanced_accuracy_score(y_test_group, y_pred)\n",
    "                \n",
    "                try:\n",
    "                    if hasattr(search.best_estimator_.named_steps['estimator'], \"predict_proba\"):\n",
    "                        y_proba = search.predict_proba(X_test_extracted)\n",
    "                        if len(np.unique(y_test_group)) == 2:\n",
    "                            result[\"roc_auc_ovr\"] = roc_auc_score(y_test_group, y_proba[:, 1] if y_proba.ndim == 2 else y_proba)\n",
    "                        else:\n",
    "                            result[\"roc_auc_ovr\"] = roc_auc_score(y_test_group, y_proba, multi_class='ovr', average='weighted')\n",
    "                    else:\n",
    "                        result[\"roc_auc_ovr\"] = None\n",
    "                except Exception as e:\n",
    "                    print(f\"ROC AUC calculation failed: {e}\")\n",
    "                    result[\"roc_auc_ovr\"] = None\n",
    "                \n",
    "                for metric in SCORING_METRICS[\"regression\"].values():\n",
    "                    result[metric] = None\n",
    "        \n",
    "            result[\"best_params\"] = str(search.best_params_)\n",
    "            results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(mdl / \"model_comparison_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789f354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>group</th>\n",
       "      <th>model</th>\n",
       "      <th>targets</th>\n",
       "      <th>r2</th>\n",
       "      <th>neg_mae</th>\n",
       "      <th>neg_rmse</th>\n",
       "      <th>neg_mape</th>\n",
       "      <th>explained_variance</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>best_params</th>\n",
       "      <th>roc_auc_ovr</th>\n",
       "      <th>neg_mean_absolute_error</th>\n",
       "      <th>neg_root_mean_squared_error</th>\n",
       "      <th>neg_mean_absolute_percentage_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regression</td>\n",
       "      <td>energy_mood</td>\n",
       "      <td>Ridge</td>\n",
       "      <td>energy, valence, danceability</td>\n",
       "      <td>0.390175</td>\n",
       "      <td>-0.142383</td>\n",
       "      <td>-0.183073</td>\n",
       "      <td>-0.674158</td>\n",
       "      <td>0.390723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OrderedDict([('estimator__estimator__alpha', 8.146216961026964), ('estimator__estimator__solver', 'sparse_cg')])</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>regression</td>\n",
       "      <td>energy_mood</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>energy, valence, danceability</td>\n",
       "      <td>0.386089</td>\n",
       "      <td>-0.145913</td>\n",
       "      <td>-0.183950</td>\n",
       "      <td>-0.711040</td>\n",
       "      <td>0.386789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OrderedDict([('estimator__estimator__alpha', 0.007165850265420658), ('estimator__estimator__selection', 'random')])</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>regression</td>\n",
       "      <td>energy_mood</td>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>energy, valence, danceability</td>\n",
       "      <td>0.381846</td>\n",
       "      <td>-0.146825</td>\n",
       "      <td>-0.184576</td>\n",
       "      <td>-0.718998</td>\n",
       "      <td>0.382614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OrderedDict([('estimator__estimator__alpha', 0.015198969741729622), ('estimator__estimator__l1_ratio', 0.5438470633401808), ('estimator__estimator__selection', 'cyclic')])</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>regression</td>\n",
       "      <td>energy_mood</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>energy, valence, danceability</td>\n",
       "      <td>0.411884</td>\n",
       "      <td>-0.141684</td>\n",
       "      <td>-0.180166</td>\n",
       "      <td>-0.734199</td>\n",
       "      <td>0.413520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OrderedDict([('estimator__estimator__max_depth', 15), ('estimator__estimator__max_features', None), ('estimator__estimator__min_samples_leaf', 3), ('estimator__estimator__min_samples_split', 2), ('estimator__estimator__n_estimators', 350)])</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>regression</td>\n",
       "      <td>energy_mood</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>energy, valence, danceability</td>\n",
       "      <td>0.439326</td>\n",
       "      <td>-0.137015</td>\n",
       "      <td>-0.175537</td>\n",
       "      <td>-0.680886</td>\n",
       "      <td>0.440332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OrderedDict([('estimator__estimator__colsample_bytree', 1.0), ('estimator__estimator__gamma', 0.05431157271809896), ('estimator__estimator__learning_rate', 0.012760248919985628), ('estimator__estimator__max_depth', 8), ('estimator__estimator__n_estimators', 648), ('estimator__estimator__subsample', 0.6)])</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task_type        group          model                        targets  \\\n",
       "0  regression  energy_mood          Ridge  energy, valence, danceability   \n",
       "1  regression  energy_mood          Lasso  energy, valence, danceability   \n",
       "2  regression  energy_mood     ElasticNet  energy, valence, danceability   \n",
       "3  regression  energy_mood  Random Forest  energy, valence, danceability   \n",
       "4  regression  energy_mood        XGBoost  energy, valence, danceability   \n",
       "\n",
       "         r2   neg_mae  neg_rmse  neg_mape  explained_variance  accuracy  \\\n",
       "0  0.390175 -0.142383 -0.183073 -0.674158            0.390723       NaN   \n",
       "1  0.386089 -0.145913 -0.183950 -0.711040            0.386789       NaN   \n",
       "2  0.381846 -0.146825 -0.184576 -0.718998            0.382614       NaN   \n",
       "3  0.411884 -0.141684 -0.180166 -0.734199            0.413520       NaN   \n",
       "4  0.439326 -0.137015 -0.175537 -0.680886            0.440332       NaN   \n",
       "\n",
       "   f1_macro  f1_weighted  precision_macro  recall_macro  balanced_accuracy  \\\n",
       "0       NaN          NaN              NaN           NaN                NaN   \n",
       "1       NaN          NaN              NaN           NaN                NaN   \n",
       "2       NaN          NaN              NaN           NaN                NaN   \n",
       "3       NaN          NaN              NaN           NaN                NaN   \n",
       "4       NaN          NaN              NaN           NaN                NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                          best_params  \\\n",
       "0                                                                                                                                                                                                    OrderedDict([('estimator__estimator__alpha', 8.146216961026964), ('estimator__estimator__solver', 'sparse_cg')])   \n",
       "1                                                                                                                                                                                                 OrderedDict([('estimator__estimator__alpha', 0.007165850265420658), ('estimator__estimator__selection', 'random')])   \n",
       "2                                                                                                                                         OrderedDict([('estimator__estimator__alpha', 0.015198969741729622), ('estimator__estimator__l1_ratio', 0.5438470633401808), ('estimator__estimator__selection', 'cyclic')])   \n",
       "3                                                                    OrderedDict([('estimator__estimator__max_depth', 15), ('estimator__estimator__max_features', None), ('estimator__estimator__min_samples_leaf', 3), ('estimator__estimator__min_samples_split', 2), ('estimator__estimator__n_estimators', 350)])   \n",
       "4  OrderedDict([('estimator__estimator__colsample_bytree', 1.0), ('estimator__estimator__gamma', 0.05431157271809896), ('estimator__estimator__learning_rate', 0.012760248919985628), ('estimator__estimator__max_depth', 8), ('estimator__estimator__n_estimators', 648), ('estimator__estimator__subsample', 0.6)])   \n",
       "\n",
       "   roc_auc_ovr  neg_mean_absolute_error  neg_root_mean_squared_error  \\\n",
       "0          NaN                      NaN                          NaN   \n",
       "1          NaN                      NaN                          NaN   \n",
       "2          NaN                      NaN                          NaN   \n",
       "3          NaN                      NaN                          NaN   \n",
       "4          NaN                      NaN                          NaN   \n",
       "\n",
       "   neg_mean_absolute_percentage_error  \n",
       "0                                 NaN  \n",
       "1                                 NaN  \n",
       "2                                 NaN  \n",
       "3                                 NaN  \n",
       "4                                 NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f87c631",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mdl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results_df = pd.read_csv(\u001b[43mmdl\u001b[49m / \u001b[33m\"\u001b[39m\u001b[33mmodel_comparison_results.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1. GET BEST MODELS FOR EACH TASK\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_best_models\u001b[39m(df):\n",
      "\u001b[31mNameError\u001b[39m: name 'mdl' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "results_df = pd.read_csv(mdl / \"model_comparison_results.csv\")\n",
    "# ============================================\n",
    "# 1. GET BEST MODELS FOR EACH TASK\n",
    "# ============================================\n",
    "\n",
    "def get_best_models(df):\n",
    "    \"\"\"\n",
    "    Find the best model for each task group based on primary metrics.\n",
    "    For regression: use r2 (higher is better)\n",
    "    For classification: use f1_weighted (higher is better)\n",
    "    \"\"\"\n",
    "    best_models = []\n",
    "    \n",
    "    # Group by task_type and group\n",
    "    for (task_type, group), group_df in df.groupby(['task_type', 'group']):\n",
    "        if task_type == 'regression':\n",
    "            # For regression, maximize R²\n",
    "            best_idx = group_df['r2'].idxmax()\n",
    "            metric_col = 'r2'\n",
    "            metric_value = group_df.loc[best_idx, 'r2']\n",
    "        else:  # classification\n",
    "            # For classification, maximize F1-weighted\n",
    "            best_idx = group_df['f1_weighted'].idxmax()\n",
    "            metric_col = 'f1_weighted'\n",
    "            metric_value = group_df.loc[best_idx, 'f1_weighted']\n",
    "        \n",
    "        best_model = group_df.loc[best_idx]\n",
    "        best_models.append({\n",
    "            'task_type': task_type,\n",
    "            'group': group,\n",
    "            'best_model': best_model['model'],\n",
    "            'targets': best_model['targets'],\n",
    "            'primary_metric': metric_col,\n",
    "            'primary_score': metric_value,\n",
    "            'best_params': best_model['best_params']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(best_models)\n",
    "\n",
    "best_models_df = get_best_models(results_df)\n",
    "print(\"=\" * 80)\n",
    "print(\"BEST MODELS FOR EACH TASK:\")\n",
    "print(\"=\" * 80)\n",
    "print(best_models_df.to_string(index=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# ============================================\n",
    "# 2. VISUALIZATIONS\n",
    "# ============================================\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 14))\n",
    "\n",
    "# --- SUBPLOT 1: Regression Tasks Comparison ---\n",
    "ax1 = plt.subplot(3, 2, 1)\n",
    "reg_df = results_df[results_df['task_type'] == 'regression'].copy()\n",
    "reg_pivot = reg_df.pivot_table(index='model', columns='group', values='r2')\n",
    "reg_pivot.plot(kind='bar', ax=ax1, colormap='viridis', width=0.8)\n",
    "ax1.set_title('Regression Models: R² Score by Task Group', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('R² Score', fontsize=12)\n",
    "ax1.set_xlabel('Model', fontsize=12)\n",
    "ax1.legend(title='Task Group', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# --- SUBPLOT 2: Regression MAE Comparison ---\n",
    "ax2 = plt.subplot(3, 2, 2)\n",
    "mae_pivot = reg_df.pivot_table(index='model', columns='group', values='neg_mae')\n",
    "mae_pivot = -mae_pivot  # Convert to positive MAE\n",
    "mae_pivot.plot(kind='bar', ax=ax2, colormap='plasma', width=0.8)\n",
    "ax2.set_title('Regression Models: MAE by Task Group', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Mean Absolute Error', fontsize=12)\n",
    "ax2.set_xlabel('Model', fontsize=12)\n",
    "ax2.legend(title='Task Group', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# --- SUBPLOT 3: Classification Accuracy ---\n",
    "ax3 = plt.subplot(3, 2, 3)\n",
    "cls_df = results_df[results_df['task_type'] == 'classification'].copy()\n",
    "acc_pivot = cls_df.pivot_table(index='model', columns='group', values='accuracy')\n",
    "acc_pivot.plot(kind='bar', ax=ax3, colormap='coolwarm', width=0.8)\n",
    "ax3.set_title('Classification Models: Accuracy by Task', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Accuracy', fontsize=12)\n",
    "ax3.set_xlabel('Model', fontsize=12)\n",
    "ax3.legend(title='Task', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "ax3.set_ylim([0, 1])\n",
    "plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# --- SUBPLOT 4: Classification F1-Weighted ---\n",
    "ax4 = plt.subplot(3, 2, 4)\n",
    "f1_pivot = cls_df.pivot_table(index='model', columns='group', values='f1_weighted')\n",
    "f1_pivot.plot(kind='bar', ax=ax4, colormap='RdYlGn', width=0.8)\n",
    "ax4.set_title('Classification Models: F1-Weighted by Task', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('F1-Weighted Score', fontsize=12)\n",
    "ax4.set_xlabel('Model', fontsize=12)\n",
    "ax4.legend(title='Task', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "ax4.set_ylim([0, 1])\n",
    "plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# --- SUBPLOT 5: Best Model Summary (Regression) ---\n",
    "ax5 = plt.subplot(3, 2, 5)\n",
    "best_reg = best_models_df[best_models_df['task_type'] == 'regression']\n",
    "x_pos = np.arange(len(best_reg))\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(best_reg)))\n",
    "bars = ax5.barh(x_pos, best_reg['primary_score'], color=colors)\n",
    "ax5.set_yticks(x_pos)\n",
    "ax5.set_yticklabels(best_reg['group'])\n",
    "ax5.set_xlabel('R² Score', fontsize=12)\n",
    "ax5.set_title('Best Regression Models per Task Group', fontsize=14, fontweight='bold')\n",
    "ax5.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels and model names\n",
    "for i, (bar, model) in enumerate(zip(bars, best_reg['best_model'])):\n",
    "    width = bar.get_width()\n",
    "    ax5.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{model}: {width:.3f}', \n",
    "             ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# --- SUBPLOT 6: Best Model Summary (Classification) ---\n",
    "ax6 = plt.subplot(3, 2, 6)\n",
    "best_cls = best_models_df[best_models_df['task_type'] == 'classification']\n",
    "x_pos = np.arange(len(best_cls))\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(best_cls)))\n",
    "bars = ax6.barh(x_pos, best_cls['primary_score'], color=colors)\n",
    "ax6.set_yticks(x_pos)\n",
    "ax6.set_yticklabels(best_cls['group'])\n",
    "ax6.set_xlabel('F1-Weighted Score', fontsize=12)\n",
    "ax6.set_title('Best Classification Models per Task', fontsize=14, fontweight='bold')\n",
    "ax6.grid(axis='x', alpha=0.3)\n",
    "ax6.set_xlim([0, 1])\n",
    "\n",
    "# Add value labels and model names\n",
    "for i, (bar, model) in enumerate(zip(bars, best_cls['best_model'])):\n",
    "    width = bar.get_width()\n",
    "    ax6.text(width + 0.02, bar.get_y() + bar.get_height()/2, \n",
    "             f'{model}: {width:.3f}', \n",
    "             ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(rep/'figures'/'model_comparison_comprehensive.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# Additional Visualization: Heatmap\n",
    "# ============================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Regression heatmap\n",
    "ax_reg = axes[0]\n",
    "reg_heatmap_data = reg_df.pivot_table(index='group', columns='model', values='r2')\n",
    "sns.heatmap(reg_heatmap_data, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "            ax=ax_reg, cbar_kws={'label': 'R² Score'}, vmin=0, vmax=0.5)\n",
    "ax_reg.set_title('Regression: R² Scores Heatmap', fontsize=14, fontweight='bold')\n",
    "ax_reg.set_xlabel('Model', fontsize=12)\n",
    "ax_reg.set_ylabel('Task Group', fontsize=12)\n",
    "\n",
    "# Classification heatmap\n",
    "ax_cls = axes[1]\n",
    "cls_heatmap_data = cls_df.pivot_table(index='group', columns='model', values='f1_weighted')\n",
    "sns.heatmap(cls_heatmap_data, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "            ax=ax_cls, cbar_kws={'label': 'F1-Weighted'}, vmin=0, vmax=1)\n",
    "ax_cls.set_title('Classification: F1-Weighted Heatmap', fontsize=14, fontweight='bold')\n",
    "ax_cls.set_xlabel('Model', fontsize=12)\n",
    "ax_cls.set_ylabel('Task', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(rep/'figures'/'model_comparison_heatmaps.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# Export Best Models Details\n",
    "# ============================================\n",
    "best_models_df.to_csv(mdl/'best_models_summary.csv', index=False)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Visualizations saved as:\")\n",
    "print(\"  - model_comparison_comprehensive.png\")\n",
    "print(\"  - model_comparison_heatmaps.png\")\n",
    "print(\"Best models summary saved as: best_models_summary.csv\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
