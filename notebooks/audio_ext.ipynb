{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37d85675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from src.music_recommender.config import Config\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, Any\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from loguru import logger\n",
    "from scipy.signal import find_peaks\n",
    "import hashlib\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4287784",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()\n",
    "asp = cfg.paths.processed / \"audio\"\n",
    "prc = cfg.paths.processed\n",
    "intr = cfg.paths.interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61fac987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        new_sr: int = 22050,\n",
    "        new_ch: int = 1,\n",
    "        n_fft: int = 2048,\n",
    "        hop_length: int = 512,\n",
    "        n_mels: int = 40,\n",
    "        target_duration: float = 30.0,\n",
    "        cache_dir: Path = intr / \"spectrogram_cache\",\n",
    "        save_cache: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.new_ch = new_ch\n",
    "        self.new_sr = new_sr\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.target_duration = target_duration\n",
    "        self.cache_dir = cache_dir\n",
    "        self.save_cache = save_cache\n",
    "        cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _resample(\n",
    "        aud_sr: Tuple[np.ndarray, float], new_sr: int\n",
    "    ) -> Tuple[np.ndarray, float]:\n",
    "        aud, sr = aud_sr\n",
    "        if sr == new_sr:\n",
    "            return aud, sr\n",
    "        if aud.ndim == 1:\n",
    "            res_aud = librosa.resample(aud, orig_sr=sr, target_sr=new_sr)\n",
    "        else:\n",
    "            res_aud = np.stack(\n",
    "                [\n",
    "                    librosa.resample(channel, orig_sr=sr, target_sr=new_sr)\n",
    "                    for channel in aud\n",
    "                ]\n",
    "            )\n",
    "        return res_aud, new_sr\n",
    "\n",
    "    @staticmethod\n",
    "    def _rechannel(\n",
    "        aud_sr: Tuple[np.ndarray, float], new_ch: int\n",
    "    ) -> Tuple[np.ndarray, float]:\n",
    "        aud, sr = aud_sr\n",
    "        n_ch = 1 if aud.ndim == 1 else aud.shape[0]\n",
    "        if n_ch == new_ch:\n",
    "            return aud_sr\n",
    "        if new_ch == 1:\n",
    "            res_aud = np.mean(aud, axis=0, keepdims=True)\n",
    "            return res_aud, sr\n",
    "        if new_ch == 2:\n",
    "            res_aud = np.stack([aud, aud])\n",
    "            return res_aud, sr\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported number of channels: {new_ch}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _pad_or_truncate(\n",
    "        aud_sr: Tuple[np.ndarray, float], target_duration: float\n",
    "    ) -> Tuple[np.ndarray, float]:\n",
    "        aud, sr = aud_sr\n",
    "\n",
    "        target_samples = int(sr * target_duration)\n",
    "        current_samples = aud.shape[-1] if aud.ndim > 1 else len(aud)\n",
    "\n",
    "        if current_samples > target_samples:\n",
    "            if aud.ndim > 1:\n",
    "                return aud[:, :target_samples], sr\n",
    "            else:\n",
    "                return aud[:target_samples], sr\n",
    "        elif current_samples < target_samples:\n",
    "            pad_samples = target_samples - current_samples\n",
    "            if aud.ndim > 1:\n",
    "                pad_width = ((0, 0), (0, pad_samples))\n",
    "            else:\n",
    "                pad_width = (0, pad_samples)\n",
    "            return np.pad(aud, pad_width, mode=\"constant\", constant_values=0), sr\n",
    "        else:\n",
    "            return aud, sr\n",
    "\n",
    "    def _get_cache_path(self, audio_path: Path) -> Path:\n",
    "        params_hash = f\"{self.n_fft}_{self.hop_length}_{self.n_mels}_{self.new_sr}_{self.new_ch}_{self.target_duration}\"\n",
    "        return self.cache_dir / f\"{audio_path.stem}_{params_hash}.npz\"\n",
    "\n",
    "    def _load_spectr(\n",
    "        self,\n",
    "        audio_path: Path,\n",
    "        n_fft: int = 2048,\n",
    "        hop_length: int = 512,\n",
    "        n_mels: int = 40,\n",
    "    ) -> Dict[str, Any]:\n",
    "        if self.save_cache:\n",
    "            cache_path = self._get_cache_path(audio_path)\n",
    "            if cache_path.exists():\n",
    "                cached = np.load(cache_path)\n",
    "                return {\n",
    "                    \"mel_spectrogram\": cached[\"mel_spectrogram\"],\n",
    "                    \"stft_spectrogram\": cached[\"stft_spectrogram\"],\n",
    "                    \"audio\": cached[\"audio\"],\n",
    "                    \"sr\": float(cached[\"sr\"]),\n",
    "                    \"path\": audio_path,\n",
    "                }\n",
    "        try:\n",
    "            aud_sr = librosa.load(audio_path)\n",
    "            aud_sr = self._pad_or_truncate(\n",
    "                aud_sr=aud_sr, target_duration=self.target_duration\n",
    "            )\n",
    "            aud_sr = self._rechannel(aud_sr=aud_sr, new_ch=self.new_ch)\n",
    "            aud_sr = self._resample(aud_sr=aud_sr, new_sr=self.new_sr)\n",
    "            aud, sr = aud_sr\n",
    "            \n",
    "            # Compute STFT for features that need it\n",
    "            stft = librosa.stft(aud, n_fft=n_fft, hop_length=hop_length)\n",
    "            stft_mag = np.abs(stft)\n",
    "            \n",
    "            # Compute mel spectrogram\n",
    "            mel_spect = librosa.feature.melspectrogram(\n",
    "                y=aud, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels\n",
    "            )\n",
    "            mel_spect_db = librosa.power_to_db(mel_spect, ref=np.max)\n",
    "\n",
    "            if self.save_cache:\n",
    "                cache_path = self._get_cache_path(audio_path)\n",
    "                np.savez_compressed(\n",
    "                    cache_path, \n",
    "                    mel_spectrogram=mel_spect_db, \n",
    "                    stft_spectrogram=stft_mag,\n",
    "                    audio=aud, \n",
    "                    sr=sr\n",
    "                )\n",
    "\n",
    "            return {\n",
    "                \"mel_spectrogram\": mel_spect_db,\n",
    "                \"stft_spectrogram\": stft_mag,\n",
    "                \"audio\": aud,\n",
    "                \"sr\": sr,\n",
    "                \"path\": audio_path\n",
    "            }\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading audio from {audio_path}: {e}\")\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X) -> np.ndarray:\n",
    "        results = []\n",
    "        for path in tqdm(X, desc=\"Loading spectrograms\"):\n",
    "            result = self._load_spectr(\n",
    "                path,\n",
    "                n_fft=self.n_fft,\n",
    "                hop_length=self.hop_length,\n",
    "                n_mels=self.n_mels,\n",
    "            )\n",
    "            results.append(result)\n",
    "        return np.array(results, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f073a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>album_title</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>release_date</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>['Kurt Vile']</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008-03-04</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.916</td>\n",
       "      <td>6</td>\n",
       "      <td>-8.162</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>111.563</td>\n",
       "      <td>161173</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237</td>\n",
       "      <td>Garbage and (Garbage and Fire)</td>\n",
       "      <td>Barnacled</td>\n",
       "      <td>6</td>\n",
       "      <td>Garbage and (garbage On Fire)</td>\n",
       "      <td>['Barnacled']</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.640</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.799</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>140.368</td>\n",
       "      <td>449467</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238</td>\n",
       "      <td>France Attacks</td>\n",
       "      <td>Barnacled</td>\n",
       "      <td>6</td>\n",
       "      <td>France Attacks</td>\n",
       "      <td>['Barnacled']</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.411</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>56.929</td>\n",
       "      <td>820707</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>Machines and Muscles</td>\n",
       "      <td>CAVE</td>\n",
       "      <td>Butthash</td>\n",
       "      <td>Machines and Muscles</td>\n",
       "      <td>['Cave']</td>\n",
       "      <td>Psychic Psummer</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009-05-26</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.918</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>108.305</td>\n",
       "      <td>236960</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459</td>\n",
       "      <td>Machines and Muscles</td>\n",
       "      <td>CAVE</td>\n",
       "      <td>Butthash</td>\n",
       "      <td>Machines and Muscles</td>\n",
       "      <td>['Cave']</td>\n",
       "      <td>Release</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-10-21</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.646</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>93.887</td>\n",
       "      <td>303680</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id                     track_title artist_name        album_title  \\\n",
       "0        10                         Freeway   Kurt Vile  Constant Hitmaker   \n",
       "1       237  Garbage and (Garbage and Fire)   Barnacled                  6   \n",
       "2       238                  France Attacks   Barnacled                  6   \n",
       "3       459            Machines and Muscles        CAVE           Butthash   \n",
       "4       459            Machines and Muscles        CAVE           Butthash   \n",
       "\n",
       "                            name        artists              album  year  \\\n",
       "0                        Freeway  ['Kurt Vile']  Constant Hitmaker  2008   \n",
       "1  Garbage and (garbage On Fire)  ['Barnacled']                  6  2003   \n",
       "2                 France Attacks  ['Barnacled']                  6  2003   \n",
       "3           Machines and Muscles       ['Cave']    Psychic Psummer  2009   \n",
       "4           Machines and Muscles       ['Cave']            Release  2014   \n",
       "\n",
       "  release_date  danceability  energy  key  loudness  mode  speechiness  \\\n",
       "0   2008-03-04         0.606   0.916    6    -8.162     1       0.0371   \n",
       "1   2003-01-01         0.280   0.640   11    -7.799     0       0.1230   \n",
       "2   2003-01-01         0.192   0.411    2    -9.445     1       0.0655   \n",
       "3   2009-05-26         0.584   0.918    7    -9.883     1       0.0345   \n",
       "4   2014-10-21         0.415   0.646    2   -12.022     1       0.0399   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  duration_ms  \\\n",
       "0        0.1400             0.356    0.1320   0.8890  111.563       161173   \n",
       "1        0.3490             0.675    0.1360   0.0537  140.368       449467   \n",
       "2        0.5390             0.709    0.0909   0.1390   56.929       820707   \n",
       "3        0.0254             0.770    0.3480   0.1140  108.305       236960   \n",
       "4        0.0189             0.948    0.0965   0.1230   93.887       303680   \n",
       "\n",
       "   time_signature  \n",
       "0             4.0  \n",
       "1             4.0  \n",
       "2             4.0  \n",
       "3             5.0  \n",
       "4             5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data = pd.read_csv(prc / \"matched_metadata.csv\")\n",
    "audio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccc510ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = audio_data[\"track_id\"].map(lambda id: asp / f\"{str(id).zfill(6)}.mp3\")\n",
    "y = audio_data[\n",
    "    [\n",
    "        \"danceability\",\n",
    "        \"energy\",\n",
    "        \"key\",\n",
    "        \"loudness\",\n",
    "        \"mode\",\n",
    "        \"speechiness\",\n",
    "        \"acousticness\",\n",
    "        \"instrumentalness\",\n",
    "        \"liveness\",\n",
    "        \"valence\",\n",
    "        \"tempo\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bdf169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efb3ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aext = SpectrogramExtractor(save_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18bb316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "class StatsFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sr: float = 22050,\n",
    "        hop_length: int = 512,\n",
    "        n_fft: int = 2048,  \n",
    "        n_mfcc: int = 13,   \n",
    "        n_chroma: int = 12, \n",
    "        f0_min: float = 65.41,  \n",
    "        f0_max: float = 2093.0,\n",
    "        enable_cache: bool = True,\n",
    "        cache_path: Path = intr / \"stats_feat\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.sr = sr\n",
    "        self.hop_length = hop_length\n",
    "        self.n_fft = n_fft\n",
    "        self.n_chroma = n_chroma\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.f0_min = f0_min\n",
    "        self.f0_max = f0_max\n",
    "        self.enable_cache = enable_cache\n",
    "        self.cache_path = cache_path\n",
    "        if self.enable_cache:\n",
    "            self.cache_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _get_cache_key(self, audio_path: str) -> str:\n",
    "        params_str = f\"{audio_path}_{self.sr}_{self.hop_length}_{self.n_fft}_{self.n_chroma}_{self.n_mfcc}_{self.f0_min}_{self.f0_max}\"\n",
    "        return hashlib.md5(params_str.encode()).hexdigest()\n",
    "    \n",
    "    def _get_cache_file(self, cache_key: str) -> Path:\n",
    "        return self.cache_path / f\"{cache_key}.pkl\"\n",
    "    \n",
    "    def _load_from_cache(self, cache_key: str):\n",
    "        cache_file = self._get_cache_file(cache_key)\n",
    "        if cache_file.exists():\n",
    "            try:\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    return pickle.load(f)\n",
    "            except:\n",
    "                return None\n",
    "        return None\n",
    "    \n",
    "    def _save_to_cache(self, cache_key: str, stats: dict):\n",
    "        \"\"\"Save features to cache\"\"\"\n",
    "        cache_file = self._get_cache_file(cache_key)\n",
    "        try:\n",
    "            with open(cache_file, 'wb') as f:\n",
    "                pickle.dump(stats, f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    @staticmethod\n",
    "    def make_stats(feature_array, features_name):\n",
    "        return {\n",
    "            f\"{features_name}_mean\": np.mean(feature_array),\n",
    "            f\"{features_name}_std\": np.std(feature_array),\n",
    "            f\"{features_name}_min\": np.min(feature_array),\n",
    "            f\"{features_name}_max\": np.max(feature_array),\n",
    "            f\"{features_name}_median\": np.median(feature_array),\n",
    "            f\"{features_name}_q25\": np.percentile(feature_array, 25),\n",
    "            f\"{features_name}_q75\": np.percentile(feature_array, 75),\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def temporal_extract(\n",
    "        audio: np.ndarray, stft_spectrogram: np.ndarray, sr: float, hop_length: int\n",
    "    ):\n",
    "\n",
    "        # Use STFT spectrogram for RMS\n",
    "        rms = librosa.feature.rms(S=stft_spectrogram, hop_length=hop_length)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=audio, hop_length=hop_length)\n",
    "\n",
    "        envelope = rms[0]\n",
    "        temporal_features = {}\n",
    "\n",
    "        if len(envelope) > 0 and np.max(envelope) > 0:\n",
    "            envelope_norm = envelope / np.max(envelope)\n",
    "\n",
    "            # Attack time (time to reach 90% of max amplitude)\n",
    "            attack_threshold = 0.9\n",
    "            attack_frame = np.argmax(envelope_norm >= attack_threshold)\n",
    "            temporal_features[\"attack_time\"] = (attack_frame * hop_length) / sr\n",
    "\n",
    "            # Temporal centroid (center of mass in time)\n",
    "            times = np.arange(len(envelope_norm)) * hop_length / sr\n",
    "            temporal_features[\"temporal_centroid\"] = np.sum(times * envelope_norm) / (\n",
    "                np.sum(envelope_norm) + 1e-8\n",
    "            )\n",
    "        else:\n",
    "            temporal_features[\"attack_time\"] = 0.0\n",
    "            temporal_features[\"temporal_centroid\"] = 0.0\n",
    "\n",
    "        frame_features = {\n",
    "            \"zcr\": zcr.flatten(),\n",
    "            \"rms\": rms.flatten(),\n",
    "        }\n",
    "\n",
    "        frame_features.update(temporal_features)\n",
    "        return frame_features\n",
    "        \n",
    "    @staticmethod\n",
    "    def spectral_extract(\n",
    "        audio: np.ndarray, stft_spectrogram: np.ndarray, sr: float, hop_length: int, n_mfcc: int\n",
    "    ):\n",
    "\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(\n",
    "            S=stft_spectrogram, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(\n",
    "            S=stft_spectrogram, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(\n",
    "            S=stft_spectrogram, sr=sr, hop_length=hop_length\n",
    "        )\n",
    "        spectral_flatness = librosa.feature.spectral_flatness(\n",
    "            S=stft_spectrogram, hop_length=hop_length\n",
    "        )\n",
    "        spectral_flux = librosa.onset.onset_strength(S=stft_spectrogram, sr=sr)\n",
    "\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            S=librosa.power_to_db(stft_spectrogram**2),\n",
    "            sr=sr,\n",
    "            n_mfcc=n_mfcc,\n",
    "            hop_length=hop_length,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"spectral_centroid\": spectral_centroid.flatten(),\n",
    "            \"spectral_bandwidth\": spectral_bandwidth.flatten(),\n",
    "            \"spectral_rolloff\": spectral_rolloff.flatten(),\n",
    "            \"spectral_flatness\": spectral_flatness.flatten(),\n",
    "            \"spectral_flux\": spectral_flux,\n",
    "            \"mfccs\": mfccs,  # Shape: (13, n_frames)\n",
    "        }    \n",
    "    @staticmethod\n",
    "    def extract_rhythm_features(audio: np.ndarray, sr: float):\n",
    "        tempo, beats = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "\n",
    "        # Compute beat strength only if beats detected\n",
    "        beat_strength = np.mean(onset_env[beats]) if len(beats) > 0 else 0.0\n",
    "        onset_rate = len(beats) / (len(audio) / sr) if len(audio) > 0 else 0.0\n",
    "        if isinstance(tempo,np.ndarray):\n",
    "            tempo = float(np.median(tempo))\n",
    "        else:\n",
    "            tempo = float(tempo)\n",
    "        return {\n",
    "            \"tempo\": tempo,  # Scalar\n",
    "            \"beat_strength\": beat_strength,  # Scalar\n",
    "            \"onset_rate\": onset_rate,  # Scalar\n",
    "            \"onset_strength\": onset_env,  # Time series\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_chroma_features(audio: np.ndarray, sr: float, hop_length: int,n_chroma:int):\n",
    "        chroma = librosa.feature.chroma_stft(y=audio, sr=sr, hop_length=hop_length,n_chroma=n_chroma)\n",
    "\n",
    "        return {\n",
    "            \"chroma\": chroma,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_hpss_features(audio: np.ndarray):\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(audio)\n",
    "\n",
    "        h_energy = np.mean(y_harmonic**2)\n",
    "        p_energy = np.mean(y_percussive**2)\n",
    "\n",
    "        return {\n",
    "            \"harmonic_percussive_ratio\": h_energy / (p_energy + 1e-8),  # Scalar\n",
    "            \"harmonic_energy\": h_energy,  # Scalar\n",
    "            \"percussive_energy\": p_energy,  # Scalar\n",
    "        }, y_harmonic  # Return harmonic component for further analysis\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_harmonic_features(y_harmonic, sr, hop_length=512, n_fft=2048, f0_min=65.41, f0_max=2093.0):\n",
    "        features = {}\n",
    "\n",
    "        # Get fundamental frequency estimates\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "            y_harmonic,\n",
    "            fmin=f0_min,\n",
    "            fmax=f0_max,\n",
    "            sr=sr,\n",
    "            hop_length=hop_length,\n",
    "        )\n",
    "\n",
    "        # Compute STFT\n",
    "        stft = librosa.stft(y_harmonic, n_fft=n_fft, hop_length=hop_length)\n",
    "        mag_spec = np.abs(stft)\n",
    "        freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "\n",
    "        # Use only voiced frames\n",
    "        valid_indices = np.where(voiced_flag)[0]\n",
    "        valid_f0 = f0[voiced_flag]\n",
    "\n",
    "        if len(valid_f0) > 0:\n",
    "            inharmonicity_values = []\n",
    "            t1_values = []\n",
    "            t2_values = []\n",
    "            t3_values = []\n",
    "\n",
    "            for idx, f0_val in zip(valid_indices, valid_f0):\n",
    "                if np.isnan(f0_val) or f0_val <= 0:\n",
    "                    continue\n",
    "\n",
    "                frame_spec = mag_spec[:, idx]\n",
    "\n",
    "                # --- INHARMONICITY CALCULATION ---\n",
    "                peaks, properties = find_peaks(\n",
    "                    frame_spec, height=np.max(frame_spec) * 0.1\n",
    "                )\n",
    "                peak_freqs = freqs[peaks]\n",
    "                peak_mags = properties[\"peak_heights\"]\n",
    "\n",
    "                if len(peak_freqs) > 0:\n",
    "                    sorted_idx = np.argsort(peak_mags)[::-1]\n",
    "                    peak_freqs = peak_freqs[sorted_idx[:10]]\n",
    "                    peak_mags = peak_mags[sorted_idx[:10]]\n",
    "\n",
    "                    deviations = []\n",
    "                    for n in range(1, min(8, len(peak_freqs) + 1)):\n",
    "                        expected_freq = f0_val * n\n",
    "                        if expected_freq < freqs[-1]:\n",
    "                            closest_idx = np.argmin(np.abs(peak_freqs - expected_freq))\n",
    "                            deviation = (\n",
    "                                np.abs(peak_freqs[closest_idx] - expected_freq)\n",
    "                                / expected_freq\n",
    "                            )\n",
    "                            deviations.append(deviation)\n",
    "\n",
    "                    if deviations:\n",
    "                        inharmonicity_values.append(np.mean(deviations))\n",
    "\n",
    "                # --- TRISTIMULUS CALCULATION ---\n",
    "                harmonic_energies = []\n",
    "                for n in range(1, 11):\n",
    "                    harmonic_freq = f0_val * n\n",
    "                    if harmonic_freq >= freqs[-1]:\n",
    "                        break\n",
    "\n",
    "                    bin_idx = np.argmin(np.abs(freqs - harmonic_freq))\n",
    "                    start_bin = max(0, bin_idx - 3)\n",
    "                    end_bin = min(len(frame_spec), bin_idx + 4)\n",
    "                    energy = np.sum(frame_spec[start_bin:end_bin])\n",
    "                    harmonic_energies.append(energy)\n",
    "\n",
    "                if len(harmonic_energies) >= 5:\n",
    "                    total_energy = np.sum(harmonic_energies) + 1e-8\n",
    "\n",
    "                    t1 = harmonic_energies[0] / total_energy\n",
    "                    t2 = np.sum(harmonic_energies[1:4]) / total_energy\n",
    "                    t3 = np.sum(harmonic_energies[4:]) / total_energy\n",
    "\n",
    "                    t1_values.append(t1)\n",
    "                    t2_values.append(t2)\n",
    "                    t3_values.append(t3)\n",
    "\n",
    "            # Aggregate features\n",
    "            features[\"inharmonicity\"] = (\n",
    "                np.mean(inharmonicity_values) if inharmonicity_values else 0.0\n",
    "            )\n",
    "            features[\"tristimulus_1\"] = np.mean(t1_values) if t1_values else 0.0\n",
    "            features[\"tristimulus_2\"] = np.mean(t2_values) if t2_values else 0.0\n",
    "            features[\"tristimulus_3\"] = np.mean(t3_values) if t3_values else 0.0\n",
    "            features[\"f0_mean\"] = np.mean(valid_f0)\n",
    "            features[\"f0_std\"] = np.std(valid_f0)\n",
    "            features[\"voiced_ratio\"] = np.sum(voiced_flag) / len(voiced_flag)\n",
    "        else:\n",
    "            # No voiced frames\n",
    "            features[\"inharmonicity\"] = 0.0\n",
    "            features[\"tristimulus_1\"] = 0.0\n",
    "            features[\"tristimulus_2\"] = 0.0\n",
    "            features[\"tristimulus_3\"] = 0.0\n",
    "            features[\"f0_mean\"] = 0.0\n",
    "            features[\"f0_std\"] = 0.0\n",
    "            features[\"voiced_ratio\"] = 0.0\n",
    "\n",
    "        return features\n",
    "    def extract_all_features(self, audio: np.ndarray, stft_spectrogram: np.ndarray):\n",
    "        all_features = {}\n",
    "\n",
    "        all_features.update(\n",
    "            self.temporal_extract(audio, stft_spectrogram, self.sr, self.hop_length)\n",
    "        )\n",
    "\n",
    "        all_features.update(\n",
    "            self.spectral_extract(audio, stft_spectrogram, self.sr, self.hop_length, self.n_mfcc)  # ← Pass n_mfcc\n",
    "        )\n",
    "\n",
    "        all_features.update(self.extract_rhythm_features(audio, self.sr))\n",
    "\n",
    "        all_features.update(\n",
    "            self.extract_chroma_features(audio, self.sr, self.hop_length,self.n_chroma)\n",
    "        )\n",
    "\n",
    "        hpss_features, y_harmonic = self.extract_hpss_features(audio)\n",
    "        all_features.update(hpss_features)\n",
    "\n",
    "        all_features.update(\n",
    "            self.extract_harmonic_features(y_harmonic, self.sr, self.hop_length, self.n_fft, self.f0_min, self.f0_max)  # ← Pass all params\n",
    "        )\n",
    "\n",
    "        return all_features\n",
    "    \n",
    "    def compute_statistics(self, features: Dict[str, Any]) -> Dict[str, float]:\n",
    "        \"\"\"Convert all features to statistics (scalars)\"\"\"\n",
    "        stats = {}\n",
    "\n",
    "        for key, val in features.items():\n",
    "            # Handle different feature types\n",
    "            if isinstance(val, (int, float, np.integer, np.floating)):\n",
    "                # Already a scalar (tempo, attack_time, etc.)\n",
    "                stats[key] = float(val)\n",
    "\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                if val.ndim == 1:\n",
    "                    # 1D time series (RMS, spectral_centroid, etc.)\n",
    "                    stats.update(self.make_stats(val, key))\n",
    "\n",
    "                elif val.ndim == 2:\n",
    "                    # 2D features (MFCCs, chroma)\n",
    "                    if key == \"mfccs\":\n",
    "                        # MFCCs: shape (13, n_frames)\n",
    "                        for i in range(val.shape[0]):  # Iterate over 13 coefficients\n",
    "                            mfcc_i = val[i, :]\n",
    "                            stats.update(self.make_stats(mfcc_i, f\"mfcc_{i}\"))\n",
    "\n",
    "                    elif key == \"chroma\":\n",
    "                        # Chroma: shape (12, n_frames)\n",
    "                        for i in range(val.shape[0]):  # Iterate over 12 pitch classes\n",
    "                            chroma_i = val[i, :]\n",
    "                            stats.update(self.make_stats(chroma_i, f\"chroma_{i}\"))\n",
    "\n",
    "                    else:\n",
    "                        # Generic 2D handling\n",
    "                        for i in range(val.shape[0]):\n",
    "                            stats.update(self.make_stats(val[i, :], f\"{key}_{i}\"))\n",
    "\n",
    "        return stats\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        feature_vectors = []\n",
    "\n",
    "        for item in tqdm(X, desc=\"Extracting features\"):\n",
    "            audio = item[\"audio\"]\n",
    "            stft_spectrogram = item[\"stft_spectrogram\"]  # Use STFT, not mel\n",
    "            audio_path = item[\"path\"]\n",
    "            \n",
    "            stats = None\n",
    "            \n",
    "            if self.enable_cache:\n",
    "                cache_key = self._get_cache_key(audio_path)\n",
    "                stats = self._load_from_cache(cache_key)\n",
    "            \n",
    "            if stats is None:\n",
    "                features = self.extract_all_features(audio, stft_spectrogram)\n",
    "                stats = self.compute_statistics(features)\n",
    "                \n",
    "                if self.enable_cache:\n",
    "                    cache_key = self._get_cache_key(audio_path)\n",
    "                    self._save_to_cache(cache_key, stats)\n",
    "            \n",
    "            feature_vectors.append(stats)\n",
    "\n",
    "        return pd.DataFrame(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dc10faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading spectrograms: 100%|██████████| 1556/1556 [07:15<00:00,  3.57it/s]\n",
      "Extracting features:  17%|█▋        | 262/1556 [20:37<2:01:12,  5.62s/it]/home/moad/desktop/music-recommender/.venv/lib/python3.11/site-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Extracting features: 100%|██████████| 1556/1556 [1:45:31<00:00,  4.07s/it]\n",
      "Loading spectrograms: 100%|██████████| 173/173 [00:48<00:00,  3.56it/s]\n",
      "Extracting features: 100%|██████████| 173/173 [12:03<00:00,  4.18s/it]\n",
      "/home/moad/desktop/music-recommender/.venv/lib/python3.11/site-packages/sklearn/pipeline.py:61: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Basic usage - extract features and train a model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Extraction pipeline\n",
    "extraction_pipeline = Pipeline([\n",
    "    ('spectrogram', SpectrogramExtractor(\n",
    "        new_sr=22050,\n",
    "        save_cache=True\n",
    "    )),\n",
    "    ('features', StatsFeatureExtractor(\n",
    "        sr=22050,\n",
    "        enable_cache=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Extract features\n",
    "X_train_extracted = extraction_pipeline.fit_transform(X_train)\n",
    "X_test_extracted = extraction_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2741f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65b69943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 77.60336160292655\n",
      "R²: 0.16735127624915133\n"
     ]
    }
   ],
   "source": [
    "# Train model on extracted features\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train_extracted, y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(X_test_extracted)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"MSE: {mean_squared_error(y_test, predictions)}\")\n",
    "print(f\"R²: {r2_score(y_test, predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
