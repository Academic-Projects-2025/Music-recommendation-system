{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3a91464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import  Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76d16041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory (works in Jupyter)\n",
    "root = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e180835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>mfcc_mean_0</th>\n",
       "      <th>mfcc_mean_1</th>\n",
       "      <th>mfcc_mean_2</th>\n",
       "      <th>mfcc_mean_3</th>\n",
       "      <th>mfcc_mean_4</th>\n",
       "      <th>mfcc_mean_5</th>\n",
       "      <th>mfcc_mean_6</th>\n",
       "      <th>mfcc_mean_7</th>\n",
       "      <th>mfcc_mean_8</th>\n",
       "      <th>mfcc_mean_9</th>\n",
       "      <th>mfcc_mean_10</th>\n",
       "      <th>mfcc_mean_11</th>\n",
       "      <th>mfcc_mean_12</th>\n",
       "      <th>mfcc_std_0</th>\n",
       "      <th>mfcc_std_1</th>\n",
       "      <th>mfcc_std_2</th>\n",
       "      <th>mfcc_std_3</th>\n",
       "      <th>mfcc_std_4</th>\n",
       "      <th>mfcc_std_5</th>\n",
       "      <th>mfcc_std_6</th>\n",
       "      <th>mfcc_std_7</th>\n",
       "      <th>mfcc_std_8</th>\n",
       "      <th>mfcc_std_9</th>\n",
       "      <th>mfcc_std_10</th>\n",
       "      <th>mfcc_std_11</th>\n",
       "      <th>mfcc_std_12</th>\n",
       "      <th>delta_mean_0</th>\n",
       "      <th>delta_mean_1</th>\n",
       "      <th>delta_mean_2</th>\n",
       "      <th>delta_mean_3</th>\n",
       "      <th>delta_mean_4</th>\n",
       "      <th>delta_mean_5</th>\n",
       "      <th>delta_mean_6</th>\n",
       "      <th>delta_mean_7</th>\n",
       "      <th>delta_mean_8</th>\n",
       "      <th>delta_mean_9</th>\n",
       "      <th>delta_mean_10</th>\n",
       "      <th>delta_mean_11</th>\n",
       "      <th>delta_mean_12</th>\n",
       "      <th>delta_std_0</th>\n",
       "      <th>delta_std_1</th>\n",
       "      <th>delta_std_2</th>\n",
       "      <th>delta_std_3</th>\n",
       "      <th>delta_std_4</th>\n",
       "      <th>delta_std_5</th>\n",
       "      <th>delta_std_6</th>\n",
       "      <th>delta_std_7</th>\n",
       "      <th>delta_std_8</th>\n",
       "      <th>delta_std_9</th>\n",
       "      <th>delta_std_10</th>\n",
       "      <th>delta_std_11</th>\n",
       "      <th>delta_std_12</th>\n",
       "      <th>delta2_mean_0</th>\n",
       "      <th>delta2_mean_1</th>\n",
       "      <th>delta2_mean_2</th>\n",
       "      <th>delta2_mean_3</th>\n",
       "      <th>delta2_mean_4</th>\n",
       "      <th>delta2_mean_5</th>\n",
       "      <th>delta2_mean_6</th>\n",
       "      <th>delta2_mean_7</th>\n",
       "      <th>delta2_mean_8</th>\n",
       "      <th>delta2_mean_9</th>\n",
       "      <th>delta2_mean_10</th>\n",
       "      <th>delta2_mean_11</th>\n",
       "      <th>delta2_mean_12</th>\n",
       "      <th>delta2_std_0</th>\n",
       "      <th>delta2_std_1</th>\n",
       "      <th>delta2_std_2</th>\n",
       "      <th>delta2_std_3</th>\n",
       "      <th>delta2_std_4</th>\n",
       "      <th>delta2_std_5</th>\n",
       "      <th>delta2_std_6</th>\n",
       "      <th>delta2_std_7</th>\n",
       "      <th>delta2_std_8</th>\n",
       "      <th>delta2_std_9</th>\n",
       "      <th>delta2_std_10</th>\n",
       "      <th>delta2_std_11</th>\n",
       "      <th>delta2_std_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109497</td>\n",
       "      <td>-14.466280</td>\n",
       "      <td>99.482414</td>\n",
       "      <td>-13.127948</td>\n",
       "      <td>43.313545</td>\n",
       "      <td>9.995256</td>\n",
       "      <td>5.399690</td>\n",
       "      <td>-5.793285</td>\n",
       "      <td>13.883069</td>\n",
       "      <td>-1.838129</td>\n",
       "      <td>2.187864</td>\n",
       "      <td>-2.674747</td>\n",
       "      <td>3.841628</td>\n",
       "      <td>-9.301169</td>\n",
       "      <td>26.336906</td>\n",
       "      <td>13.115074</td>\n",
       "      <td>12.082673</td>\n",
       "      <td>10.713166</td>\n",
       "      <td>7.633686</td>\n",
       "      <td>5.559512</td>\n",
       "      <td>5.984026</td>\n",
       "      <td>5.907621</td>\n",
       "      <td>5.963255</td>\n",
       "      <td>5.159916</td>\n",
       "      <td>5.725162</td>\n",
       "      <td>4.790164</td>\n",
       "      <td>5.414805</td>\n",
       "      <td>0.220803</td>\n",
       "      <td>0.009053</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>-0.003279</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>4.416480</td>\n",
       "      <td>2.527710</td>\n",
       "      <td>1.879202</td>\n",
       "      <td>1.614143</td>\n",
       "      <td>1.372204</td>\n",
       "      <td>0.916860</td>\n",
       "      <td>1.072609</td>\n",
       "      <td>1.153425</td>\n",
       "      <td>1.141011</td>\n",
       "      <td>0.906527</td>\n",
       "      <td>1.142041</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>1.012290</td>\n",
       "      <td>-0.135776</td>\n",
       "      <td>-0.035974</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>-0.013851</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.009171</td>\n",
       "      <td>-0.006136</td>\n",
       "      <td>-0.009151</td>\n",
       "      <td>-0.006148</td>\n",
       "      <td>-0.006779</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>2.662576</td>\n",
       "      <td>1.463119</td>\n",
       "      <td>1.183564</td>\n",
       "      <td>1.022441</td>\n",
       "      <td>0.859411</td>\n",
       "      <td>0.726815</td>\n",
       "      <td>0.796010</td>\n",
       "      <td>0.860587</td>\n",
       "      <td>0.880833</td>\n",
       "      <td>0.730460</td>\n",
       "      <td>0.814752</td>\n",
       "      <td>0.704768</td>\n",
       "      <td>0.741921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53666</td>\n",
       "      <td>-52.185890</td>\n",
       "      <td>99.239310</td>\n",
       "      <td>-19.818560</td>\n",
       "      <td>34.841200</td>\n",
       "      <td>-4.830251</td>\n",
       "      <td>7.452331</td>\n",
       "      <td>0.821418</td>\n",
       "      <td>-0.551589</td>\n",
       "      <td>0.541429</td>\n",
       "      <td>8.759988</td>\n",
       "      <td>-2.642872</td>\n",
       "      <td>6.468830</td>\n",
       "      <td>-2.554433</td>\n",
       "      <td>17.970594</td>\n",
       "      <td>16.446632</td>\n",
       "      <td>10.712290</td>\n",
       "      <td>8.822542</td>\n",
       "      <td>7.811877</td>\n",
       "      <td>5.619895</td>\n",
       "      <td>6.609158</td>\n",
       "      <td>6.775237</td>\n",
       "      <td>6.076496</td>\n",
       "      <td>6.250626</td>\n",
       "      <td>5.909140</td>\n",
       "      <td>5.741867</td>\n",
       "      <td>5.448841</td>\n",
       "      <td>0.012402</td>\n",
       "      <td>-0.007382</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>-0.001866</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>-0.008891</td>\n",
       "      <td>-0.007915</td>\n",
       "      <td>3.199941</td>\n",
       "      <td>2.723585</td>\n",
       "      <td>2.005160</td>\n",
       "      <td>1.703189</td>\n",
       "      <td>1.259007</td>\n",
       "      <td>1.013505</td>\n",
       "      <td>1.200884</td>\n",
       "      <td>1.042044</td>\n",
       "      <td>1.084845</td>\n",
       "      <td>1.036201</td>\n",
       "      <td>1.091861</td>\n",
       "      <td>0.978752</td>\n",
       "      <td>1.000591</td>\n",
       "      <td>-0.011197</td>\n",
       "      <td>-0.015572</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>-0.001591</td>\n",
       "      <td>-0.006339</td>\n",
       "      <td>-0.008179</td>\n",
       "      <td>-0.007428</td>\n",
       "      <td>-0.002442</td>\n",
       "      <td>-0.002701</td>\n",
       "      <td>-0.006067</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>-0.005737</td>\n",
       "      <td>2.597663</td>\n",
       "      <td>1.668799</td>\n",
       "      <td>1.340824</td>\n",
       "      <td>1.059314</td>\n",
       "      <td>0.872083</td>\n",
       "      <td>0.693278</td>\n",
       "      <td>0.744236</td>\n",
       "      <td>0.724987</td>\n",
       "      <td>0.736523</td>\n",
       "      <td>0.742568</td>\n",
       "      <td>0.732206</td>\n",
       "      <td>0.654933</td>\n",
       "      <td>0.686628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55400</td>\n",
       "      <td>-37.400524</td>\n",
       "      <td>124.763824</td>\n",
       "      <td>-36.813070</td>\n",
       "      <td>21.995646</td>\n",
       "      <td>2.225886</td>\n",
       "      <td>21.032818</td>\n",
       "      <td>3.546124</td>\n",
       "      <td>10.978546</td>\n",
       "      <td>-5.663468</td>\n",
       "      <td>1.670306</td>\n",
       "      <td>-1.866043</td>\n",
       "      <td>4.414843</td>\n",
       "      <td>0.263866</td>\n",
       "      <td>25.074936</td>\n",
       "      <td>15.589418</td>\n",
       "      <td>11.059312</td>\n",
       "      <td>9.996412</td>\n",
       "      <td>8.603876</td>\n",
       "      <td>6.485661</td>\n",
       "      <td>7.064106</td>\n",
       "      <td>4.818400</td>\n",
       "      <td>4.594680</td>\n",
       "      <td>4.897986</td>\n",
       "      <td>4.508664</td>\n",
       "      <td>5.303911</td>\n",
       "      <td>5.510609</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>-0.004898</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.013210</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>4.374987</td>\n",
       "      <td>2.896857</td>\n",
       "      <td>1.517322</td>\n",
       "      <td>1.221072</td>\n",
       "      <td>1.538684</td>\n",
       "      <td>0.871887</td>\n",
       "      <td>1.157159</td>\n",
       "      <td>0.796285</td>\n",
       "      <td>0.784595</td>\n",
       "      <td>0.881469</td>\n",
       "      <td>0.744571</td>\n",
       "      <td>0.868556</td>\n",
       "      <td>0.739550</td>\n",
       "      <td>-0.057128</td>\n",
       "      <td>0.014514</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>-0.001030</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>3.734957</td>\n",
       "      <td>1.728411</td>\n",
       "      <td>1.449256</td>\n",
       "      <td>1.055884</td>\n",
       "      <td>0.866639</td>\n",
       "      <td>0.662977</td>\n",
       "      <td>0.788613</td>\n",
       "      <td>0.562866</td>\n",
       "      <td>0.613871</td>\n",
       "      <td>0.658512</td>\n",
       "      <td>0.639172</td>\n",
       "      <td>0.613510</td>\n",
       "      <td>0.579289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10589</td>\n",
       "      <td>-380.002870</td>\n",
       "      <td>181.902250</td>\n",
       "      <td>-65.369286</td>\n",
       "      <td>10.870298</td>\n",
       "      <td>16.465267</td>\n",
       "      <td>-47.996254</td>\n",
       "      <td>-3.810154</td>\n",
       "      <td>-8.473990</td>\n",
       "      <td>-42.449270</td>\n",
       "      <td>-8.006559</td>\n",
       "      <td>-6.592747</td>\n",
       "      <td>-21.923280</td>\n",
       "      <td>-0.598965</td>\n",
       "      <td>65.707250</td>\n",
       "      <td>25.217339</td>\n",
       "      <td>45.143143</td>\n",
       "      <td>18.352695</td>\n",
       "      <td>13.137667</td>\n",
       "      <td>17.607540</td>\n",
       "      <td>8.177697</td>\n",
       "      <td>8.135131</td>\n",
       "      <td>13.139120</td>\n",
       "      <td>8.508199</td>\n",
       "      <td>9.304217</td>\n",
       "      <td>8.381541</td>\n",
       "      <td>8.219736</td>\n",
       "      <td>0.189026</td>\n",
       "      <td>0.083782</td>\n",
       "      <td>-0.052729</td>\n",
       "      <td>-0.005151</td>\n",
       "      <td>-0.000277</td>\n",
       "      <td>-0.026846</td>\n",
       "      <td>-0.010993</td>\n",
       "      <td>-0.013700</td>\n",
       "      <td>-0.027458</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>-0.008412</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>7.055398</td>\n",
       "      <td>3.073463</td>\n",
       "      <td>4.952223</td>\n",
       "      <td>2.348252</td>\n",
       "      <td>1.871211</td>\n",
       "      <td>1.966379</td>\n",
       "      <td>1.128496</td>\n",
       "      <td>1.124765</td>\n",
       "      <td>1.474231</td>\n",
       "      <td>1.269974</td>\n",
       "      <td>1.269533</td>\n",
       "      <td>1.053716</td>\n",
       "      <td>1.284437</td>\n",
       "      <td>-0.054324</td>\n",
       "      <td>-0.050451</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>-0.010189</td>\n",
       "      <td>-0.012286</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>-0.004870</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>3.407578</td>\n",
       "      <td>1.517492</td>\n",
       "      <td>2.385228</td>\n",
       "      <td>1.016233</td>\n",
       "      <td>0.909341</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>0.677607</td>\n",
       "      <td>0.646453</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>0.651975</td>\n",
       "      <td>0.664161</td>\n",
       "      <td>0.649972</td>\n",
       "      <td>0.697728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55923</td>\n",
       "      <td>-18.598597</td>\n",
       "      <td>71.360760</td>\n",
       "      <td>-16.790304</td>\n",
       "      <td>51.837322</td>\n",
       "      <td>-2.433789</td>\n",
       "      <td>12.741719</td>\n",
       "      <td>6.080010</td>\n",
       "      <td>5.622876</td>\n",
       "      <td>0.253179</td>\n",
       "      <td>3.234265</td>\n",
       "      <td>-1.363661</td>\n",
       "      <td>1.043400</td>\n",
       "      <td>-7.887192</td>\n",
       "      <td>21.666910</td>\n",
       "      <td>18.164318</td>\n",
       "      <td>15.200961</td>\n",
       "      <td>13.062137</td>\n",
       "      <td>8.761080</td>\n",
       "      <td>9.015322</td>\n",
       "      <td>8.081576</td>\n",
       "      <td>7.085149</td>\n",
       "      <td>7.131298</td>\n",
       "      <td>6.381190</td>\n",
       "      <td>5.982719</td>\n",
       "      <td>5.748267</td>\n",
       "      <td>5.225229</td>\n",
       "      <td>0.066447</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>-0.015879</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>-0.011966</td>\n",
       "      <td>-0.006075</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.003642</td>\n",
       "      <td>-0.020094</td>\n",
       "      <td>4.150834</td>\n",
       "      <td>2.444548</td>\n",
       "      <td>2.649830</td>\n",
       "      <td>2.237288</td>\n",
       "      <td>1.532949</td>\n",
       "      <td>1.640232</td>\n",
       "      <td>1.431198</td>\n",
       "      <td>1.290325</td>\n",
       "      <td>1.357411</td>\n",
       "      <td>1.095927</td>\n",
       "      <td>1.101842</td>\n",
       "      <td>1.017437</td>\n",
       "      <td>0.991913</td>\n",
       "      <td>-0.040584</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>-0.011483</td>\n",
       "      <td>-0.005313</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>-0.004375</td>\n",
       "      <td>3.154008</td>\n",
       "      <td>1.603595</td>\n",
       "      <td>1.603042</td>\n",
       "      <td>1.200993</td>\n",
       "      <td>0.932761</td>\n",
       "      <td>0.907508</td>\n",
       "      <td>0.857162</td>\n",
       "      <td>0.766474</td>\n",
       "      <td>0.761395</td>\n",
       "      <td>0.690974</td>\n",
       "      <td>0.697007</td>\n",
       "      <td>0.658661</td>\n",
       "      <td>0.626155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  mfcc_mean_0  mfcc_mean_1  mfcc_mean_2  mfcc_mean_3  mfcc_mean_4  \\\n",
       "0    109497   -14.466280    99.482414   -13.127948    43.313545     9.995256   \n",
       "1     53666   -52.185890    99.239310   -19.818560    34.841200    -4.830251   \n",
       "2     55400   -37.400524   124.763824   -36.813070    21.995646     2.225886   \n",
       "3     10589  -380.002870   181.902250   -65.369286    10.870298    16.465267   \n",
       "4     55923   -18.598597    71.360760   -16.790304    51.837322    -2.433789   \n",
       "\n",
       "   mfcc_mean_5  mfcc_mean_6  mfcc_mean_7  mfcc_mean_8  mfcc_mean_9  \\\n",
       "0     5.399690    -5.793285    13.883069    -1.838129     2.187864   \n",
       "1     7.452331     0.821418    -0.551589     0.541429     8.759988   \n",
       "2    21.032818     3.546124    10.978546    -5.663468     1.670306   \n",
       "3   -47.996254    -3.810154    -8.473990   -42.449270    -8.006559   \n",
       "4    12.741719     6.080010     5.622876     0.253179     3.234265   \n",
       "\n",
       "   mfcc_mean_10  mfcc_mean_11  mfcc_mean_12  mfcc_std_0  mfcc_std_1  \\\n",
       "0     -2.674747      3.841628     -9.301169   26.336906   13.115074   \n",
       "1     -2.642872      6.468830     -2.554433   17.970594   16.446632   \n",
       "2     -1.866043      4.414843      0.263866   25.074936   15.589418   \n",
       "3     -6.592747    -21.923280     -0.598965   65.707250   25.217339   \n",
       "4     -1.363661      1.043400     -7.887192   21.666910   18.164318   \n",
       "\n",
       "   mfcc_std_2  mfcc_std_3  mfcc_std_4  mfcc_std_5  mfcc_std_6  mfcc_std_7  \\\n",
       "0   12.082673   10.713166    7.633686    5.559512    5.984026    5.907621   \n",
       "1   10.712290    8.822542    7.811877    5.619895    6.609158    6.775237   \n",
       "2   11.059312    9.996412    8.603876    6.485661    7.064106    4.818400   \n",
       "3   45.143143   18.352695   13.137667   17.607540    8.177697    8.135131   \n",
       "4   15.200961   13.062137    8.761080    9.015322    8.081576    7.085149   \n",
       "\n",
       "   mfcc_std_8  mfcc_std_9  mfcc_std_10  mfcc_std_11  mfcc_std_12  \\\n",
       "0    5.963255    5.159916     5.725162     4.790164     5.414805   \n",
       "1    6.076496    6.250626     5.909140     5.741867     5.448841   \n",
       "2    4.594680    4.897986     4.508664     5.303911     5.510609   \n",
       "3   13.139120    8.508199     9.304217     8.381541     8.219736   \n",
       "4    7.131298    6.381190     5.982719     5.748267     5.225229   \n",
       "\n",
       "   delta_mean_0  delta_mean_1  delta_mean_2  delta_mean_3  delta_mean_4  \\\n",
       "0      0.220803      0.009053     -0.002882     -0.003425      0.000750   \n",
       "1      0.012402     -0.007382     -0.005155      0.002076     -0.001866   \n",
       "2      0.058065     -0.010560      0.011036      0.009491     -0.004898   \n",
       "3      0.189026      0.083782     -0.052729     -0.005151     -0.000277   \n",
       "4      0.066447      0.025715     -0.015879      0.012799     -0.001647   \n",
       "\n",
       "   delta_mean_5  delta_mean_6  delta_mean_7  delta_mean_8  delta_mean_9  \\\n",
       "0      0.004600     -0.003279      0.011742      0.006375      0.001650   \n",
       "1     -0.001652     -0.000474     -0.000553     -0.000199      0.011042   \n",
       "2      0.002371      0.013210      0.016682      0.005274      0.004574   \n",
       "3     -0.026846     -0.010993     -0.013700     -0.027458      0.001743   \n",
       "4     -0.011966     -0.006075      0.003678      0.003172      0.002557   \n",
       "\n",
       "   delta_mean_10  delta_mean_11  delta_mean_12  delta_std_0  delta_std_1  \\\n",
       "0       0.000165      -0.000724       0.005746     4.416480     2.527710   \n",
       "1       0.004957      -0.008891      -0.007915     3.199941     2.723585   \n",
       "2       0.003347       0.005777       0.008513     4.374987     2.896857   \n",
       "3       0.007929      -0.008412      -0.008311     7.055398     3.073463   \n",
       "4      -0.000214      -0.003642      -0.020094     4.150834     2.444548   \n",
       "\n",
       "   delta_std_2  delta_std_3  delta_std_4  delta_std_5  delta_std_6  \\\n",
       "0     1.879202     1.614143     1.372204     0.916860     1.072609   \n",
       "1     2.005160     1.703189     1.259007     1.013505     1.200884   \n",
       "2     1.517322     1.221072     1.538684     0.871887     1.157159   \n",
       "3     4.952223     2.348252     1.871211     1.966379     1.128496   \n",
       "4     2.649830     2.237288     1.532949     1.640232     1.431198   \n",
       "\n",
       "   delta_std_7  delta_std_8  delta_std_9  delta_std_10  delta_std_11  \\\n",
       "0     1.153425     1.141011     0.906527      1.142041      0.910949   \n",
       "1     1.042044     1.084845     1.036201      1.091861      0.978752   \n",
       "2     0.796285     0.784595     0.881469      0.744571      0.868556   \n",
       "3     1.124765     1.474231     1.269974      1.269533      1.053716   \n",
       "4     1.290325     1.357411     1.095927      1.101842      1.017437   \n",
       "\n",
       "   delta_std_12  delta2_mean_0  delta2_mean_1  delta2_mean_2  delta2_mean_3  \\\n",
       "0      1.012290      -0.135776      -0.035974       0.004075      -0.013851   \n",
       "1      1.000591      -0.011197      -0.015572      -0.007065      -0.002806   \n",
       "2      0.739550      -0.057128       0.014514      -0.004043       0.006608   \n",
       "3      1.284437      -0.054324      -0.050451       0.013551      -0.010189   \n",
       "4      0.991913      -0.040584       0.003627       0.011505       0.000095   \n",
       "\n",
       "   delta2_mean_4  delta2_mean_5  delta2_mean_6  delta2_mean_7  delta2_mean_8  \\\n",
       "0      -0.004475      -0.001072      -0.002500      -0.009171      -0.006136   \n",
       "1      -0.001591      -0.006339      -0.008179      -0.007428      -0.002442   \n",
       "2       0.012310      -0.003013       0.000503      -0.001101       0.002705   \n",
       "3      -0.012286       0.013427      -0.004870      -0.000656       0.008195   \n",
       "4       0.000420      -0.011483      -0.005313       0.010726       0.000119   \n",
       "\n",
       "   delta2_mean_9  delta2_mean_10  delta2_mean_11  delta2_mean_12  \\\n",
       "0      -0.009151       -0.006148       -0.006779       -0.001375   \n",
       "1      -0.002701       -0.006067       -0.005588       -0.005737   \n",
       "2      -0.000753       -0.001030        0.000794       -0.001403   \n",
       "3      -0.000025        0.005310        0.010322       -0.001069   \n",
       "4      -0.002157       -0.000055        0.005269       -0.004375   \n",
       "\n",
       "   delta2_std_0  delta2_std_1  delta2_std_2  delta2_std_3  delta2_std_4  \\\n",
       "0      2.662576      1.463119      1.183564      1.022441      0.859411   \n",
       "1      2.597663      1.668799      1.340824      1.059314      0.872083   \n",
       "2      3.734957      1.728411      1.449256      1.055884      0.866639   \n",
       "3      3.407578      1.517492      2.385228      1.016233      0.909341   \n",
       "4      3.154008      1.603595      1.603042      1.200993      0.932761   \n",
       "\n",
       "   delta2_std_5  delta2_std_6  delta2_std_7  delta2_std_8  delta2_std_9  \\\n",
       "0      0.726815      0.796010      0.860587      0.880833      0.730460   \n",
       "1      0.693278      0.744236      0.724987      0.736523      0.742568   \n",
       "2      0.662977      0.788613      0.562866      0.613871      0.658512   \n",
       "3      0.999600      0.677607      0.646453      0.789100      0.651975   \n",
       "4      0.907508      0.857162      0.766474      0.761395      0.690974   \n",
       "\n",
       "   delta2_std_10  delta2_std_11  delta2_std_12  \n",
       "0       0.814752       0.704768       0.741921  \n",
       "1       0.732206       0.654933       0.686628  \n",
       "2       0.639172       0.613510       0.579289  \n",
       "3       0.664161       0.649972       0.697728  \n",
       "4       0.697007       0.658661       0.626155  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the full path\n",
    "MFCC_df = pd.read_csv(root / 'data/processed/mfcc_features.csv')\n",
    "\n",
    "MFCC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b723d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "matched_df = pd.read_csv(root / 'data/processed/matched_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2b2f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_targets = ['energy',  \n",
    "           'loudness', 'speechiness', 'acousticness', \n",
    "           'instrumentalness', 'liveness', 'valence', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89a0fa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.916</td>\n",
       "      <td>-8.162</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>111.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-7.799</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>140.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-9.445</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>56.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>0.918</td>\n",
       "      <td>-9.883</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>108.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459</td>\n",
       "      <td>0.646</td>\n",
       "      <td>-12.022</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>93.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  energy  loudness  speechiness  acousticness  instrumentalness  \\\n",
       "0        10   0.916    -8.162       0.0371        0.1400             0.356   \n",
       "1       237   0.640    -7.799       0.1230        0.3490             0.675   \n",
       "2       238   0.411    -9.445       0.0655        0.5390             0.709   \n",
       "3       459   0.918    -9.883       0.0345        0.0254             0.770   \n",
       "4       459   0.646   -12.022       0.0399        0.0189             0.948   \n",
       "\n",
       "   liveness  valence    tempo  \n",
       "0    0.1320   0.8890  111.563  \n",
       "1    0.1360   0.0537  140.368  \n",
       "2    0.0909   0.1390   56.929  \n",
       "3    0.3480   0.1140  108.305  \n",
       "4    0.0965   0.1230   93.887  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_df_target = matched_df[['track_id'] + continuous_targets]\n",
    "matched_df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3d32ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>mfcc_mean_0</th>\n",
       "      <th>mfcc_mean_1</th>\n",
       "      <th>mfcc_mean_2</th>\n",
       "      <th>mfcc_mean_3</th>\n",
       "      <th>mfcc_mean_4</th>\n",
       "      <th>mfcc_mean_5</th>\n",
       "      <th>mfcc_mean_6</th>\n",
       "      <th>mfcc_mean_7</th>\n",
       "      <th>mfcc_mean_8</th>\n",
       "      <th>mfcc_mean_9</th>\n",
       "      <th>mfcc_mean_10</th>\n",
       "      <th>mfcc_mean_11</th>\n",
       "      <th>mfcc_mean_12</th>\n",
       "      <th>mfcc_std_0</th>\n",
       "      <th>mfcc_std_1</th>\n",
       "      <th>mfcc_std_2</th>\n",
       "      <th>mfcc_std_3</th>\n",
       "      <th>mfcc_std_4</th>\n",
       "      <th>mfcc_std_5</th>\n",
       "      <th>mfcc_std_6</th>\n",
       "      <th>mfcc_std_7</th>\n",
       "      <th>mfcc_std_8</th>\n",
       "      <th>mfcc_std_9</th>\n",
       "      <th>mfcc_std_10</th>\n",
       "      <th>mfcc_std_11</th>\n",
       "      <th>mfcc_std_12</th>\n",
       "      <th>delta_mean_0</th>\n",
       "      <th>delta_mean_1</th>\n",
       "      <th>delta_mean_2</th>\n",
       "      <th>delta_mean_3</th>\n",
       "      <th>delta_mean_4</th>\n",
       "      <th>delta_mean_5</th>\n",
       "      <th>delta_mean_6</th>\n",
       "      <th>delta_mean_7</th>\n",
       "      <th>delta_mean_8</th>\n",
       "      <th>delta_mean_9</th>\n",
       "      <th>delta_mean_10</th>\n",
       "      <th>delta_mean_11</th>\n",
       "      <th>delta_mean_12</th>\n",
       "      <th>delta_std_0</th>\n",
       "      <th>delta_std_1</th>\n",
       "      <th>delta_std_2</th>\n",
       "      <th>delta_std_3</th>\n",
       "      <th>delta_std_4</th>\n",
       "      <th>delta_std_5</th>\n",
       "      <th>delta_std_6</th>\n",
       "      <th>delta_std_7</th>\n",
       "      <th>delta_std_8</th>\n",
       "      <th>delta_std_9</th>\n",
       "      <th>delta_std_10</th>\n",
       "      <th>delta_std_11</th>\n",
       "      <th>delta_std_12</th>\n",
       "      <th>delta2_mean_0</th>\n",
       "      <th>delta2_mean_1</th>\n",
       "      <th>delta2_mean_2</th>\n",
       "      <th>delta2_mean_3</th>\n",
       "      <th>delta2_mean_4</th>\n",
       "      <th>delta2_mean_5</th>\n",
       "      <th>delta2_mean_6</th>\n",
       "      <th>delta2_mean_7</th>\n",
       "      <th>delta2_mean_8</th>\n",
       "      <th>delta2_mean_9</th>\n",
       "      <th>delta2_mean_10</th>\n",
       "      <th>delta2_mean_11</th>\n",
       "      <th>delta2_mean_12</th>\n",
       "      <th>delta2_std_0</th>\n",
       "      <th>delta2_std_1</th>\n",
       "      <th>delta2_std_2</th>\n",
       "      <th>delta2_std_3</th>\n",
       "      <th>delta2_std_4</th>\n",
       "      <th>delta2_std_5</th>\n",
       "      <th>delta2_std_6</th>\n",
       "      <th>delta2_std_7</th>\n",
       "      <th>delta2_std_8</th>\n",
       "      <th>delta2_std_9</th>\n",
       "      <th>delta2_std_10</th>\n",
       "      <th>delta2_std_11</th>\n",
       "      <th>delta2_std_12</th>\n",
       "      <th>energy</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109497</td>\n",
       "      <td>-14.466280</td>\n",
       "      <td>99.482414</td>\n",
       "      <td>-13.127948</td>\n",
       "      <td>43.313545</td>\n",
       "      <td>9.995256</td>\n",
       "      <td>5.399690</td>\n",
       "      <td>-5.793285</td>\n",
       "      <td>13.883069</td>\n",
       "      <td>-1.838129</td>\n",
       "      <td>2.187864</td>\n",
       "      <td>-2.674747</td>\n",
       "      <td>3.841628</td>\n",
       "      <td>-9.301169</td>\n",
       "      <td>26.336906</td>\n",
       "      <td>13.115074</td>\n",
       "      <td>12.082673</td>\n",
       "      <td>10.713166</td>\n",
       "      <td>7.633686</td>\n",
       "      <td>5.559512</td>\n",
       "      <td>5.984026</td>\n",
       "      <td>5.907621</td>\n",
       "      <td>5.963255</td>\n",
       "      <td>5.159916</td>\n",
       "      <td>5.725162</td>\n",
       "      <td>4.790164</td>\n",
       "      <td>5.414805</td>\n",
       "      <td>0.220803</td>\n",
       "      <td>0.009053</td>\n",
       "      <td>-0.002882</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>-0.003279</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.006375</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>4.416480</td>\n",
       "      <td>2.527710</td>\n",
       "      <td>1.879202</td>\n",
       "      <td>1.614143</td>\n",
       "      <td>1.372204</td>\n",
       "      <td>0.916860</td>\n",
       "      <td>1.072609</td>\n",
       "      <td>1.153425</td>\n",
       "      <td>1.141011</td>\n",
       "      <td>0.906527</td>\n",
       "      <td>1.142041</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>1.012290</td>\n",
       "      <td>-0.135776</td>\n",
       "      <td>-0.035974</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>-0.013851</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>-0.009171</td>\n",
       "      <td>-0.006136</td>\n",
       "      <td>-0.009151</td>\n",
       "      <td>-0.006148</td>\n",
       "      <td>-0.006779</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>2.662576</td>\n",
       "      <td>1.463119</td>\n",
       "      <td>1.183564</td>\n",
       "      <td>1.022441</td>\n",
       "      <td>0.859411</td>\n",
       "      <td>0.726815</td>\n",
       "      <td>0.796010</td>\n",
       "      <td>0.860587</td>\n",
       "      <td>0.880833</td>\n",
       "      <td>0.730460</td>\n",
       "      <td>0.814752</td>\n",
       "      <td>0.704768</td>\n",
       "      <td>0.741921</td>\n",
       "      <td>0.897</td>\n",
       "      <td>-8.232</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.189</td>\n",
       "      <td>105.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53666</td>\n",
       "      <td>-52.185890</td>\n",
       "      <td>99.239310</td>\n",
       "      <td>-19.818560</td>\n",
       "      <td>34.841200</td>\n",
       "      <td>-4.830251</td>\n",
       "      <td>7.452331</td>\n",
       "      <td>0.821418</td>\n",
       "      <td>-0.551589</td>\n",
       "      <td>0.541429</td>\n",
       "      <td>8.759988</td>\n",
       "      <td>-2.642872</td>\n",
       "      <td>6.468830</td>\n",
       "      <td>-2.554433</td>\n",
       "      <td>17.970594</td>\n",
       "      <td>16.446632</td>\n",
       "      <td>10.712290</td>\n",
       "      <td>8.822542</td>\n",
       "      <td>7.811877</td>\n",
       "      <td>5.619895</td>\n",
       "      <td>6.609158</td>\n",
       "      <td>6.775237</td>\n",
       "      <td>6.076496</td>\n",
       "      <td>6.250626</td>\n",
       "      <td>5.909140</td>\n",
       "      <td>5.741867</td>\n",
       "      <td>5.448841</td>\n",
       "      <td>0.012402</td>\n",
       "      <td>-0.007382</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>-0.001866</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>-0.008891</td>\n",
       "      <td>-0.007915</td>\n",
       "      <td>3.199941</td>\n",
       "      <td>2.723585</td>\n",
       "      <td>2.005160</td>\n",
       "      <td>1.703189</td>\n",
       "      <td>1.259007</td>\n",
       "      <td>1.013505</td>\n",
       "      <td>1.200884</td>\n",
       "      <td>1.042044</td>\n",
       "      <td>1.084845</td>\n",
       "      <td>1.036201</td>\n",
       "      <td>1.091861</td>\n",
       "      <td>0.978752</td>\n",
       "      <td>1.000591</td>\n",
       "      <td>-0.011197</td>\n",
       "      <td>-0.015572</td>\n",
       "      <td>-0.007065</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>-0.001591</td>\n",
       "      <td>-0.006339</td>\n",
       "      <td>-0.008179</td>\n",
       "      <td>-0.007428</td>\n",
       "      <td>-0.002442</td>\n",
       "      <td>-0.002701</td>\n",
       "      <td>-0.006067</td>\n",
       "      <td>-0.005588</td>\n",
       "      <td>-0.005737</td>\n",
       "      <td>2.597663</td>\n",
       "      <td>1.668799</td>\n",
       "      <td>1.340824</td>\n",
       "      <td>1.059314</td>\n",
       "      <td>0.872083</td>\n",
       "      <td>0.693278</td>\n",
       "      <td>0.744236</td>\n",
       "      <td>0.724987</td>\n",
       "      <td>0.736523</td>\n",
       "      <td>0.742568</td>\n",
       "      <td>0.732206</td>\n",
       "      <td>0.654933</td>\n",
       "      <td>0.686628</td>\n",
       "      <td>0.874</td>\n",
       "      <td>-5.437</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.500</td>\n",
       "      <td>139.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55400</td>\n",
       "      <td>-37.400524</td>\n",
       "      <td>124.763824</td>\n",
       "      <td>-36.813070</td>\n",
       "      <td>21.995646</td>\n",
       "      <td>2.225886</td>\n",
       "      <td>21.032818</td>\n",
       "      <td>3.546124</td>\n",
       "      <td>10.978546</td>\n",
       "      <td>-5.663468</td>\n",
       "      <td>1.670306</td>\n",
       "      <td>-1.866043</td>\n",
       "      <td>4.414843</td>\n",
       "      <td>0.263866</td>\n",
       "      <td>25.074936</td>\n",
       "      <td>15.589418</td>\n",
       "      <td>11.059312</td>\n",
       "      <td>9.996412</td>\n",
       "      <td>8.603876</td>\n",
       "      <td>6.485661</td>\n",
       "      <td>7.064106</td>\n",
       "      <td>4.818400</td>\n",
       "      <td>4.594680</td>\n",
       "      <td>4.897986</td>\n",
       "      <td>4.508664</td>\n",
       "      <td>5.303911</td>\n",
       "      <td>5.510609</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>-0.004898</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.013210</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>4.374987</td>\n",
       "      <td>2.896857</td>\n",
       "      <td>1.517322</td>\n",
       "      <td>1.221072</td>\n",
       "      <td>1.538684</td>\n",
       "      <td>0.871887</td>\n",
       "      <td>1.157159</td>\n",
       "      <td>0.796285</td>\n",
       "      <td>0.784595</td>\n",
       "      <td>0.881469</td>\n",
       "      <td>0.744571</td>\n",
       "      <td>0.868556</td>\n",
       "      <td>0.739550</td>\n",
       "      <td>-0.057128</td>\n",
       "      <td>0.014514</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.012310</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>-0.001030</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>3.734957</td>\n",
       "      <td>1.728411</td>\n",
       "      <td>1.449256</td>\n",
       "      <td>1.055884</td>\n",
       "      <td>0.866639</td>\n",
       "      <td>0.662977</td>\n",
       "      <td>0.788613</td>\n",
       "      <td>0.562866</td>\n",
       "      <td>0.613871</td>\n",
       "      <td>0.658512</td>\n",
       "      <td>0.639172</td>\n",
       "      <td>0.613510</td>\n",
       "      <td>0.579289</td>\n",
       "      <td>0.979</td>\n",
       "      <td>-4.001</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.106</td>\n",
       "      <td>62.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10589</td>\n",
       "      <td>-380.002870</td>\n",
       "      <td>181.902250</td>\n",
       "      <td>-65.369286</td>\n",
       "      <td>10.870298</td>\n",
       "      <td>16.465267</td>\n",
       "      <td>-47.996254</td>\n",
       "      <td>-3.810154</td>\n",
       "      <td>-8.473990</td>\n",
       "      <td>-42.449270</td>\n",
       "      <td>-8.006559</td>\n",
       "      <td>-6.592747</td>\n",
       "      <td>-21.923280</td>\n",
       "      <td>-0.598965</td>\n",
       "      <td>65.707250</td>\n",
       "      <td>25.217339</td>\n",
       "      <td>45.143143</td>\n",
       "      <td>18.352695</td>\n",
       "      <td>13.137667</td>\n",
       "      <td>17.607540</td>\n",
       "      <td>8.177697</td>\n",
       "      <td>8.135131</td>\n",
       "      <td>13.139120</td>\n",
       "      <td>8.508199</td>\n",
       "      <td>9.304217</td>\n",
       "      <td>8.381541</td>\n",
       "      <td>8.219736</td>\n",
       "      <td>0.189026</td>\n",
       "      <td>0.083782</td>\n",
       "      <td>-0.052729</td>\n",
       "      <td>-0.005151</td>\n",
       "      <td>-0.000277</td>\n",
       "      <td>-0.026846</td>\n",
       "      <td>-0.010993</td>\n",
       "      <td>-0.013700</td>\n",
       "      <td>-0.027458</td>\n",
       "      <td>0.001743</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>-0.008412</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>7.055398</td>\n",
       "      <td>3.073463</td>\n",
       "      <td>4.952223</td>\n",
       "      <td>2.348252</td>\n",
       "      <td>1.871211</td>\n",
       "      <td>1.966379</td>\n",
       "      <td>1.128496</td>\n",
       "      <td>1.124765</td>\n",
       "      <td>1.474231</td>\n",
       "      <td>1.269974</td>\n",
       "      <td>1.269533</td>\n",
       "      <td>1.053716</td>\n",
       "      <td>1.284437</td>\n",
       "      <td>-0.054324</td>\n",
       "      <td>-0.050451</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>-0.010189</td>\n",
       "      <td>-0.012286</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>-0.004870</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.010322</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>3.407578</td>\n",
       "      <td>1.517492</td>\n",
       "      <td>2.385228</td>\n",
       "      <td>1.016233</td>\n",
       "      <td>0.909341</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>0.677607</td>\n",
       "      <td>0.646453</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>0.651975</td>\n",
       "      <td>0.664161</td>\n",
       "      <td>0.649972</td>\n",
       "      <td>0.697728</td>\n",
       "      <td>0.338</td>\n",
       "      <td>-7.432</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.767000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.247</td>\n",
       "      <td>94.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55923</td>\n",
       "      <td>-18.598597</td>\n",
       "      <td>71.360760</td>\n",
       "      <td>-16.790304</td>\n",
       "      <td>51.837322</td>\n",
       "      <td>-2.433789</td>\n",
       "      <td>12.741719</td>\n",
       "      <td>6.080010</td>\n",
       "      <td>5.622876</td>\n",
       "      <td>0.253179</td>\n",
       "      <td>3.234265</td>\n",
       "      <td>-1.363661</td>\n",
       "      <td>1.043400</td>\n",
       "      <td>-7.887192</td>\n",
       "      <td>21.666910</td>\n",
       "      <td>18.164318</td>\n",
       "      <td>15.200961</td>\n",
       "      <td>13.062137</td>\n",
       "      <td>8.761080</td>\n",
       "      <td>9.015322</td>\n",
       "      <td>8.081576</td>\n",
       "      <td>7.085149</td>\n",
       "      <td>7.131298</td>\n",
       "      <td>6.381190</td>\n",
       "      <td>5.982719</td>\n",
       "      <td>5.748267</td>\n",
       "      <td>5.225229</td>\n",
       "      <td>0.066447</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>-0.015879</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>-0.011966</td>\n",
       "      <td>-0.006075</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.003642</td>\n",
       "      <td>-0.020094</td>\n",
       "      <td>4.150834</td>\n",
       "      <td>2.444548</td>\n",
       "      <td>2.649830</td>\n",
       "      <td>2.237288</td>\n",
       "      <td>1.532949</td>\n",
       "      <td>1.640232</td>\n",
       "      <td>1.431198</td>\n",
       "      <td>1.290325</td>\n",
       "      <td>1.357411</td>\n",
       "      <td>1.095927</td>\n",
       "      <td>1.101842</td>\n",
       "      <td>1.017437</td>\n",
       "      <td>0.991913</td>\n",
       "      <td>-0.040584</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>-0.011483</td>\n",
       "      <td>-0.005313</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.002157</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>-0.004375</td>\n",
       "      <td>3.154008</td>\n",
       "      <td>1.603595</td>\n",
       "      <td>1.603042</td>\n",
       "      <td>1.200993</td>\n",
       "      <td>0.932761</td>\n",
       "      <td>0.907508</td>\n",
       "      <td>0.857162</td>\n",
       "      <td>0.766474</td>\n",
       "      <td>0.761395</td>\n",
       "      <td>0.690974</td>\n",
       "      <td>0.697007</td>\n",
       "      <td>0.658661</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>0.943</td>\n",
       "      <td>-5.427</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.121000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.566</td>\n",
       "      <td>79.396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  mfcc_mean_0  mfcc_mean_1  mfcc_mean_2  mfcc_mean_3  mfcc_mean_4  \\\n",
       "0    109497   -14.466280    99.482414   -13.127948    43.313545     9.995256   \n",
       "1     53666   -52.185890    99.239310   -19.818560    34.841200    -4.830251   \n",
       "2     55400   -37.400524   124.763824   -36.813070    21.995646     2.225886   \n",
       "3     10589  -380.002870   181.902250   -65.369286    10.870298    16.465267   \n",
       "4     55923   -18.598597    71.360760   -16.790304    51.837322    -2.433789   \n",
       "\n",
       "   mfcc_mean_5  mfcc_mean_6  mfcc_mean_7  mfcc_mean_8  mfcc_mean_9  \\\n",
       "0     5.399690    -5.793285    13.883069    -1.838129     2.187864   \n",
       "1     7.452331     0.821418    -0.551589     0.541429     8.759988   \n",
       "2    21.032818     3.546124    10.978546    -5.663468     1.670306   \n",
       "3   -47.996254    -3.810154    -8.473990   -42.449270    -8.006559   \n",
       "4    12.741719     6.080010     5.622876     0.253179     3.234265   \n",
       "\n",
       "   mfcc_mean_10  mfcc_mean_11  mfcc_mean_12  mfcc_std_0  mfcc_std_1  \\\n",
       "0     -2.674747      3.841628     -9.301169   26.336906   13.115074   \n",
       "1     -2.642872      6.468830     -2.554433   17.970594   16.446632   \n",
       "2     -1.866043      4.414843      0.263866   25.074936   15.589418   \n",
       "3     -6.592747    -21.923280     -0.598965   65.707250   25.217339   \n",
       "4     -1.363661      1.043400     -7.887192   21.666910   18.164318   \n",
       "\n",
       "   mfcc_std_2  mfcc_std_3  mfcc_std_4  mfcc_std_5  mfcc_std_6  mfcc_std_7  \\\n",
       "0   12.082673   10.713166    7.633686    5.559512    5.984026    5.907621   \n",
       "1   10.712290    8.822542    7.811877    5.619895    6.609158    6.775237   \n",
       "2   11.059312    9.996412    8.603876    6.485661    7.064106    4.818400   \n",
       "3   45.143143   18.352695   13.137667   17.607540    8.177697    8.135131   \n",
       "4   15.200961   13.062137    8.761080    9.015322    8.081576    7.085149   \n",
       "\n",
       "   mfcc_std_8  mfcc_std_9  mfcc_std_10  mfcc_std_11  mfcc_std_12  \\\n",
       "0    5.963255    5.159916     5.725162     4.790164     5.414805   \n",
       "1    6.076496    6.250626     5.909140     5.741867     5.448841   \n",
       "2    4.594680    4.897986     4.508664     5.303911     5.510609   \n",
       "3   13.139120    8.508199     9.304217     8.381541     8.219736   \n",
       "4    7.131298    6.381190     5.982719     5.748267     5.225229   \n",
       "\n",
       "   delta_mean_0  delta_mean_1  delta_mean_2  delta_mean_3  delta_mean_4  \\\n",
       "0      0.220803      0.009053     -0.002882     -0.003425      0.000750   \n",
       "1      0.012402     -0.007382     -0.005155      0.002076     -0.001866   \n",
       "2      0.058065     -0.010560      0.011036      0.009491     -0.004898   \n",
       "3      0.189026      0.083782     -0.052729     -0.005151     -0.000277   \n",
       "4      0.066447      0.025715     -0.015879      0.012799     -0.001647   \n",
       "\n",
       "   delta_mean_5  delta_mean_6  delta_mean_7  delta_mean_8  delta_mean_9  \\\n",
       "0      0.004600     -0.003279      0.011742      0.006375      0.001650   \n",
       "1     -0.001652     -0.000474     -0.000553     -0.000199      0.011042   \n",
       "2      0.002371      0.013210      0.016682      0.005274      0.004574   \n",
       "3     -0.026846     -0.010993     -0.013700     -0.027458      0.001743   \n",
       "4     -0.011966     -0.006075      0.003678      0.003172      0.002557   \n",
       "\n",
       "   delta_mean_10  delta_mean_11  delta_mean_12  delta_std_0  delta_std_1  \\\n",
       "0       0.000165      -0.000724       0.005746     4.416480     2.527710   \n",
       "1       0.004957      -0.008891      -0.007915     3.199941     2.723585   \n",
       "2       0.003347       0.005777       0.008513     4.374987     2.896857   \n",
       "3       0.007929      -0.008412      -0.008311     7.055398     3.073463   \n",
       "4      -0.000214      -0.003642      -0.020094     4.150834     2.444548   \n",
       "\n",
       "   delta_std_2  delta_std_3  delta_std_4  delta_std_5  delta_std_6  \\\n",
       "0     1.879202     1.614143     1.372204     0.916860     1.072609   \n",
       "1     2.005160     1.703189     1.259007     1.013505     1.200884   \n",
       "2     1.517322     1.221072     1.538684     0.871887     1.157159   \n",
       "3     4.952223     2.348252     1.871211     1.966379     1.128496   \n",
       "4     2.649830     2.237288     1.532949     1.640232     1.431198   \n",
       "\n",
       "   delta_std_7  delta_std_8  delta_std_9  delta_std_10  delta_std_11  \\\n",
       "0     1.153425     1.141011     0.906527      1.142041      0.910949   \n",
       "1     1.042044     1.084845     1.036201      1.091861      0.978752   \n",
       "2     0.796285     0.784595     0.881469      0.744571      0.868556   \n",
       "3     1.124765     1.474231     1.269974      1.269533      1.053716   \n",
       "4     1.290325     1.357411     1.095927      1.101842      1.017437   \n",
       "\n",
       "   delta_std_12  delta2_mean_0  delta2_mean_1  delta2_mean_2  delta2_mean_3  \\\n",
       "0      1.012290      -0.135776      -0.035974       0.004075      -0.013851   \n",
       "1      1.000591      -0.011197      -0.015572      -0.007065      -0.002806   \n",
       "2      0.739550      -0.057128       0.014514      -0.004043       0.006608   \n",
       "3      1.284437      -0.054324      -0.050451       0.013551      -0.010189   \n",
       "4      0.991913      -0.040584       0.003627       0.011505       0.000095   \n",
       "\n",
       "   delta2_mean_4  delta2_mean_5  delta2_mean_6  delta2_mean_7  delta2_mean_8  \\\n",
       "0      -0.004475      -0.001072      -0.002500      -0.009171      -0.006136   \n",
       "1      -0.001591      -0.006339      -0.008179      -0.007428      -0.002442   \n",
       "2       0.012310      -0.003013       0.000503      -0.001101       0.002705   \n",
       "3      -0.012286       0.013427      -0.004870      -0.000656       0.008195   \n",
       "4       0.000420      -0.011483      -0.005313       0.010726       0.000119   \n",
       "\n",
       "   delta2_mean_9  delta2_mean_10  delta2_mean_11  delta2_mean_12  \\\n",
       "0      -0.009151       -0.006148       -0.006779       -0.001375   \n",
       "1      -0.002701       -0.006067       -0.005588       -0.005737   \n",
       "2      -0.000753       -0.001030        0.000794       -0.001403   \n",
       "3      -0.000025        0.005310        0.010322       -0.001069   \n",
       "4      -0.002157       -0.000055        0.005269       -0.004375   \n",
       "\n",
       "   delta2_std_0  delta2_std_1  delta2_std_2  delta2_std_3  delta2_std_4  \\\n",
       "0      2.662576      1.463119      1.183564      1.022441      0.859411   \n",
       "1      2.597663      1.668799      1.340824      1.059314      0.872083   \n",
       "2      3.734957      1.728411      1.449256      1.055884      0.866639   \n",
       "3      3.407578      1.517492      2.385228      1.016233      0.909341   \n",
       "4      3.154008      1.603595      1.603042      1.200993      0.932761   \n",
       "\n",
       "   delta2_std_5  delta2_std_6  delta2_std_7  delta2_std_8  delta2_std_9  \\\n",
       "0      0.726815      0.796010      0.860587      0.880833      0.730460   \n",
       "1      0.693278      0.744236      0.724987      0.736523      0.742568   \n",
       "2      0.662977      0.788613      0.562866      0.613871      0.658512   \n",
       "3      0.999600      0.677607      0.646453      0.789100      0.651975   \n",
       "4      0.907508      0.857162      0.766474      0.761395      0.690974   \n",
       "\n",
       "   delta2_std_10  delta2_std_11  delta2_std_12  energy  loudness  speechiness  \\\n",
       "0       0.814752       0.704768       0.741921   0.897    -8.232       0.0874   \n",
       "1       0.732206       0.654933       0.686628   0.874    -5.437       0.0447   \n",
       "2       0.639172       0.613510       0.579289   0.979    -4.001       0.0893   \n",
       "3       0.664161       0.649972       0.697728   0.338    -7.432       0.0317   \n",
       "4       0.697007       0.658661       0.626155   0.943    -5.427       0.0900   \n",
       "\n",
       "   acousticness  instrumentalness  liveness  valence    tempo  \n",
       "0      0.000140          0.363000     0.113    0.189  105.241  \n",
       "1      0.000019          0.925000     0.318    0.500  139.800  \n",
       "2      0.000065          0.001590     0.807    0.106   62.513  \n",
       "3      0.767000          0.000008     0.113    0.247   94.139  \n",
       "4      0.121000          0.000000     0.340    0.566   79.396  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_targets_df = matched_df_target[[\"track_id\"]+ continuous_targets]\n",
    "merged_df = MFCC_df.merge(c_targets_df, on = 'track_id')\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34875f53",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6a6d797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "Best hyperparameters for energy:\n",
      "  C: 0.1\n",
      "  epsilon: 0.01\n",
      "  gamma: 0.01\n",
      "\n",
      "Performance Metrics for energy:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.1514\n",
      "  MAE:  0.1093\n",
      "  R:   0.6759\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.1627\n",
      "  MAE:  0.1274\n",
      "  R:   0.6262\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "Best hyperparameters for loudness:\n",
      "  C: 100\n",
      "  epsilon: 0.2\n",
      "  gamma: 0.001\n",
      "\n",
      "Performance Metrics for loudness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 2.9976\n",
      "  MAE:  1.9158\n",
      "  R:   0.5814\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.2748\n",
      "  MAE:  2.4861\n",
      "  R:   0.4638\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "Best hyperparameters for speechiness:\n",
      "  C: 0.1\n",
      "  epsilon: 0.01\n",
      "  gamma: scale\n",
      "\n",
      "Performance Metrics for speechiness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.0562\n",
      "  MAE:  0.0196\n",
      "  R:   0.3780\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.0678\n",
      "  MAE:  0.0299\n",
      "  R:   0.1200\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "Best hyperparameters for acousticness:\n",
      "  C: 1\n",
      "  epsilon: 0.15\n",
      "  gamma: 0.001\n",
      "\n",
      "Performance Metrics for acousticness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.2424\n",
      "  MAE:  0.1929\n",
      "  R:   0.5307\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.2456\n",
      "  MAE:  0.1959\n",
      "  R:   0.4935\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "Best hyperparameters for instrumentalness:\n",
      "  C: 1\n",
      "  epsilon: 0.2\n",
      "  gamma: 0.001\n",
      "\n",
      "Performance Metrics for instrumentalness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.3154\n",
      "  MAE:  0.2673\n",
      "  R:   0.2750\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.3389\n",
      "  MAE:  0.2859\n",
      "  R:   0.1388\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "Best hyperparameters for liveness:\n",
      "  C: 1\n",
      "  epsilon: 0.1\n",
      "  gamma: 0.001\n",
      "\n",
      "Performance Metrics for liveness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.1530\n",
      "  MAE:  0.1108\n",
      "  R:   0.0845\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.1484\n",
      "  MAE:  0.1145\n",
      "  R:   0.0325\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "Best hyperparameters for valence:\n",
      "  C: 0.1\n",
      "  epsilon: 0.1\n",
      "  gamma: 0.01\n",
      "\n",
      "Performance Metrics for valence:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.1979\n",
      "  MAE:  0.1596\n",
      "  R:   0.4324\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.2154\n",
      "  MAE:  0.1742\n",
      "  R:   0.3100\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "\n",
      "Best hyperparameters for tempo:\n",
      "  C: 10\n",
      "  epsilon: 0.2\n",
      "  gamma: auto\n",
      "\n",
      "Performance Metrics for tempo:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 26.9724\n",
      "  MAE:  19.9098\n",
      "  R:   0.2583\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 27.4247\n",
      "  MAE:  21.5147\n",
      "  R:   0.0992\n"
     ]
    }
   ],
   "source": [
    "X = merged_df.drop(['track_id'] + continuous_targets, axis=1)\n",
    "\n",
    "# Define parameter grid optimized for RBF kernel\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100, 1000],              \n",
    "    'gamma': ['scale', 'auto', 0.0001, 0.001, 0.01, 0.1, 1, 10],  \n",
    "    'epsilon': [0.001, 0.01, 0.05, 0.1, 0.15, 0.2]    \n",
    "}\n",
    "\n",
    "# SVR \n",
    "svr = SVR(kernel='rbf')\n",
    "\n",
    "# Grid search (5-fold cross-validation)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svr,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all CPU cores for faster processing\n",
    ")\n",
    "\n",
    "\n",
    "results =[]\n",
    "\n",
    "for target in continuous_targets:\n",
    "    \n",
    "    y = merged_df[target]\n",
    "    \n",
    "    # Train test split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Create a NEW scaler for each target\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Scaling\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Fitting the model\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # The best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"\\nBest hyperparameters for {target}:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = best_model.predict(X_train_scaled)\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Performance metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        'target': target,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'best_model': best_model,\n",
    "        'scaler': scaler\n",
    "    })\n",
    "\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics for {target}:\")\n",
    "    print(f\"\\nTraining Set:\")\n",
    "    print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"  MAE:  {train_mae:.4f}\")\n",
    "    print(f\"  R:   {train_r2:.4f}\")\n",
    "    print(f\"\\nTest Set:\")\n",
    "    print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  MAE:  {test_mae:.4f}\")\n",
    "    print(f\"  R:   {test_r2:.4f}\")\n",
    "\n",
    "\n",
    "# Convert to DataFrame for easy comparison\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3cafea7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>best_model</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>energy</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>0.151385</td>\n",
       "      <td>0.162687</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.626211</td>\n",
       "      <td>SVR(C=0.1, epsilon=0.01, gamma=0.01)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loudness</td>\n",
       "      <td>{'C': 100, 'epsilon': 0.2, 'gamma': 0.001}</td>\n",
       "      <td>2.997630</td>\n",
       "      <td>3.274823</td>\n",
       "      <td>0.581409</td>\n",
       "      <td>0.463764</td>\n",
       "      <td>SVR(C=100, epsilon=0.2, gamma=0.001)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.01, 'gamma': 'scale'}</td>\n",
       "      <td>0.056214</td>\n",
       "      <td>0.067831</td>\n",
       "      <td>0.378032</td>\n",
       "      <td>0.120037</td>\n",
       "      <td>SVR(C=0.1, epsilon=0.01)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acousticness</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.15, 'gamma': 0.001}</td>\n",
       "      <td>0.242435</td>\n",
       "      <td>0.245616</td>\n",
       "      <td>0.530722</td>\n",
       "      <td>0.493493</td>\n",
       "      <td>SVR(C=1, epsilon=0.15, gamma=0.001)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.2, 'gamma': 0.001}</td>\n",
       "      <td>0.315394</td>\n",
       "      <td>0.338894</td>\n",
       "      <td>0.274985</td>\n",
       "      <td>0.138757</td>\n",
       "      <td>SVR(C=1, epsilon=0.2, gamma=0.001)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>liveness</td>\n",
       "      <td>{'C': 1, 'epsilon': 0.1, 'gamma': 0.001}</td>\n",
       "      <td>0.152968</td>\n",
       "      <td>0.148412</td>\n",
       "      <td>0.084517</td>\n",
       "      <td>0.032472</td>\n",
       "      <td>SVR(C=1, gamma=0.001)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>valence</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.1, 'gamma': 0.01}</td>\n",
       "      <td>0.197901</td>\n",
       "      <td>0.215388</td>\n",
       "      <td>0.432425</td>\n",
       "      <td>0.309995</td>\n",
       "      <td>SVR(C=0.1, gamma=0.01)</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tempo</td>\n",
       "      <td>{'C': 10, 'epsilon': 0.2, 'gamma': 'auto'}</td>\n",
       "      <td>26.972359</td>\n",
       "      <td>27.424687</td>\n",
       "      <td>0.258293</td>\n",
       "      <td>0.099215</td>\n",
       "      <td>SVR(C=10, epsilon=0.2, gamma='auto')</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target                                    best_params  \\\n",
       "0            energy     {'C': 0.1, 'epsilon': 0.01, 'gamma': 0.01}   \n",
       "1          loudness     {'C': 100, 'epsilon': 0.2, 'gamma': 0.001}   \n",
       "2       speechiness  {'C': 0.1, 'epsilon': 0.01, 'gamma': 'scale'}   \n",
       "3      acousticness      {'C': 1, 'epsilon': 0.15, 'gamma': 0.001}   \n",
       "4  instrumentalness       {'C': 1, 'epsilon': 0.2, 'gamma': 0.001}   \n",
       "5          liveness       {'C': 1, 'epsilon': 0.1, 'gamma': 0.001}   \n",
       "6           valence      {'C': 0.1, 'epsilon': 0.1, 'gamma': 0.01}   \n",
       "7             tempo     {'C': 10, 'epsilon': 0.2, 'gamma': 'auto'}   \n",
       "\n",
       "   train_rmse  test_rmse  train_r2   test_r2  \\\n",
       "0    0.151385   0.162687  0.675912  0.626211   \n",
       "1    2.997630   3.274823  0.581409  0.463764   \n",
       "2    0.056214   0.067831  0.378032  0.120037   \n",
       "3    0.242435   0.245616  0.530722  0.493493   \n",
       "4    0.315394   0.338894  0.274985  0.138757   \n",
       "5    0.152968   0.148412  0.084517  0.032472   \n",
       "6    0.197901   0.215388  0.432425  0.309995   \n",
       "7   26.972359  27.424687  0.258293  0.099215   \n",
       "\n",
       "                             best_model            scaler  \n",
       "0  SVR(C=0.1, epsilon=0.01, gamma=0.01)  StandardScaler()  \n",
       "1  SVR(C=100, epsilon=0.2, gamma=0.001)  StandardScaler()  \n",
       "2              SVR(C=0.1, epsilon=0.01)  StandardScaler()  \n",
       "3   SVR(C=1, epsilon=0.15, gamma=0.001)  StandardScaler()  \n",
       "4    SVR(C=1, epsilon=0.2, gamma=0.001)  StandardScaler()  \n",
       "5                 SVR(C=1, gamma=0.001)  StandardScaler()  \n",
       "6                SVR(C=0.1, gamma=0.01)  StandardScaler()  \n",
       "7  SVR(C=10, epsilon=0.2, gamma='auto')  StandardScaler()  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6448caf",
   "metadata": {},
   "source": [
    "Ecellent genereralisation: Energy and Accousticness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4587da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved energy model\n",
      " Saved acousticness model\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "for target in ['energy', 'acousticness']:\n",
    "    # Get model data from results_df\n",
    "    row = results_df[results_df['target'] == target].iloc[0]\n",
    "    \n",
    "    # Create directory\n",
    "    (root / 'models' / target).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save model and scaler\n",
    "    joblib.dump(row['best_model'], root / 'models' / target / f'svr_{target}_model.pkl')\n",
    "    joblib.dump(row['scaler'], root / 'models' / target / f'svr_{target}_scaler.pkl')\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'target': target,\n",
    "        'model_type': 'SVR',\n",
    "        'trained_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'hyperparameters': row['best_params'],\n",
    "        'performance': {\n",
    "            'test_r2': float(row['test_r2']),\n",
    "            'test_rmse': float(row['test_rmse'])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(root / 'models' / target / f'svr_{target}_metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\" Saved {target} model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a4beb",
   "metadata": {},
   "source": [
    "**Random Forest Regresor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afae11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_well_svr = ['loudness', 'speechiness', 'instrumentalness', 'liveness', 'valence', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2f43a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST WITH STRONGER REGULARIZATION\n",
      "Total combinations: 1458\n",
      "Processing target: loudness\n",
      "\n",
      "Fitting Random Forest with regularization...\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "\n",
      "Best hyperparameters for loudness:\n",
      "  bootstrap: True\n",
      "  max_depth: 15\n",
      "  max_features: sqrt\n",
      "  max_samples: 0.9\n",
      "  min_impurity_decrease: 0.01\n",
      "  min_samples_leaf: 5\n",
      "  min_samples_split: 10\n",
      "  n_estimators: 200\n",
      "\n",
      "Out-of-Bag R Score: 0.4151\n",
      "\n",
      "Cross-Validation:\n",
      "  Train MSE: 6.0484\n",
      "  Val MSE:   12.5675\n",
      "  Ratio:     2.08\n",
      "\n",
      "Performance Metrics for loudness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 2.4525\n",
      "  MAE:  1.7280\n",
      "  R:   0.7198\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.2103\n",
      "  MAE:  2.4708\n",
      "  R:   0.4847\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.2351\n",
      "  Moderate overfitting\n",
      "Processing target: speechiness\n",
      "\n",
      "Fitting Random Forest with regularization...\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "\n",
      "Best hyperparameters for speechiness:\n",
      "  bootstrap: True\n",
      "  max_depth: 5\n",
      "  max_features: sqrt\n",
      "  max_samples: 0.7\n",
      "  min_impurity_decrease: 0.0001\n",
      "  min_samples_leaf: 15\n",
      "  min_samples_split: 10\n",
      "  n_estimators: 300\n",
      "\n",
      "Out-of-Bag R Score: 0.0755\n",
      "\n",
      "Cross-Validation:\n",
      "  Train MSE: 0.0043\n",
      "  Val MSE:   0.0047\n",
      "  Ratio:     1.09\n",
      "\n",
      "Performance Metrics for speechiness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.0658\n",
      "  MAE:  0.0351\n",
      "  R:   0.1470\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.0686\n",
      "  MAE:  0.0351\n",
      "  R:   0.0990\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.0480\n",
      "   Good generalization\n",
      "Processing target: instrumentalness\n",
      "\n",
      "Fitting Random Forest with regularization...\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "\n",
      "Best hyperparameters for instrumentalness:\n",
      "  bootstrap: True\n",
      "  max_depth: 15\n",
      "  max_features: log2\n",
      "  max_samples: 0.9\n",
      "  min_impurity_decrease: 0.0001\n",
      "  min_samples_leaf: 5\n",
      "  min_samples_split: 10\n",
      "  n_estimators: 300\n",
      "\n",
      "Out-of-Bag R Score: 0.2178\n",
      "\n",
      "Cross-Validation:\n",
      "  Train MSE: 0.0514\n",
      "  Val MSE:   0.1081\n",
      "  Ratio:     2.10\n",
      "\n",
      "Performance Metrics for instrumentalness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.2271\n",
      "  MAE:  0.1968\n",
      "  R:   0.6240\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.3261\n",
      "  MAE:  0.2864\n",
      "  R:   0.2025\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.4215\n",
      "  High overfitting - features may not capture target well\n",
      "Processing target: liveness\n",
      "\n",
      "Fitting Random Forest with regularization...\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "\n",
      "Best hyperparameters for liveness:\n",
      "  bootstrap: True\n",
      "  max_depth: 15\n",
      "  max_features: sqrt\n",
      "  max_samples: 0.7\n",
      "  min_impurity_decrease: 0.0001\n",
      "  min_samples_leaf: 5\n",
      "  min_samples_split: 10\n",
      "  n_estimators: 300\n",
      "\n",
      "Out-of-Bag R Score: 0.0361\n",
      "\n",
      "Cross-Validation:\n",
      "  Train MSE: 0.0154\n",
      "  Val MSE:   0.0242\n",
      "  Ratio:     1.57\n",
      "\n",
      "Performance Metrics for liveness:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.1264\n",
      "  MAE:  0.0927\n",
      "  R:   0.3751\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.1480\n",
      "  MAE:  0.1134\n",
      "  R:   0.0376\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.3375\n",
      "  High overfitting - features may not capture target well\n",
      "Processing target: tempo\n",
      "\n",
      "Fitting Random Forest with regularization...\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "\n",
      "Best hyperparameters for tempo:\n",
      "  bootstrap: True\n",
      "  max_depth: 15\n",
      "  max_features: sqrt\n",
      "  max_samples: 0.9\n",
      "  min_impurity_decrease: 0.0001\n",
      "  min_samples_leaf: 5\n",
      "  min_samples_split: 10\n",
      "  n_estimators: 100\n",
      "\n",
      "Out-of-Bag R Score: 0.0751\n",
      "\n",
      "Cross-Validation:\n",
      "  Train MSE: 401.2139\n",
      "  Val MSE:   905.5527\n",
      "  Ratio:     2.26\n",
      "\n",
      "Performance Metrics for tempo:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 20.0437\n",
      "  MAE:  15.4798\n",
      "  R:   0.5904\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 27.5220\n",
      "  MAE:  21.7850\n",
      "  R:   0.0928\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.4976\n",
      "  High overfitting - features may not capture target well\n",
      "Processing target: valence\n",
      "\n",
      "Fitting Random Forest with regularization...\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "\n",
      "Best hyperparameters for valence:\n",
      "  bootstrap: True\n",
      "  max_depth: 15\n",
      "  max_features: sqrt\n",
      "  max_samples: 0.9\n",
      "  min_impurity_decrease: 0.0001\n",
      "  min_samples_leaf: 5\n",
      "  min_samples_split: 10\n",
      "  n_estimators: 300\n",
      "\n",
      "Out-of-Bag R Score: 0.2679\n",
      "\n",
      "Cross-Validation:\n",
      "  Train MSE: 0.0223\n",
      "  Val MSE:   0.0514\n",
      "  Ratio:     2.30\n",
      "\n",
      "Performance Metrics for valence:\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.1504\n",
      "  MAE:  0.1233\n",
      "  R:   0.6721\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.2089\n",
      "  MAE:  0.1726\n",
      "  R:   0.3508\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.3213\n",
      "  High overfitting - features may not capture target well\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare features\n",
    "X = merged_df.drop(['track_id'] + continuous_targets, axis=1)\n",
    "\n",
    "\n",
    "print(\"RANDOM FOREST WITH STRONGER REGULARIZATION\")\n",
    "\n",
    "\n",
    "# IMPROVED PARAMETER GRID - Focus on preventing overfitting\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15],  # Limit tree depth more aggressively\n",
    "    'min_samples_split': [10, 20, 30],  # Require more samples to split\n",
    "    'min_samples_leaf': [5, 10, 15],  # Require more samples in leaf nodes\n",
    "    'max_features': ['sqrt', 'log2'],  # Limit features considered\n",
    "    'bootstrap': [True],  # Always use bootstrap for regularization\n",
    "    'max_samples': [0.7, 0.8, 0.9],  # Subsample training data\n",
    "    'min_impurity_decrease': [0.0001, 0.001, 0.01]  # Require minimum improvement\n",
    "}\n",
    "\n",
    "print(f\"Total combinations: {np.prod([len(v) for v in param_grid.values()])}\")\n",
    "\n",
    "\n",
    "# Random Forest with OOB scoring\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "results_rf2 = []\n",
    "\n",
    "# Define targets that need extra regularization\n",
    "high_overfitting_targets = ['loudness', 'speechiness', 'instrumentalness', \n",
    "                             'liveness', 'tempo', 'valence']\n",
    "\n",
    "for target in high_overfitting_targets:\n",
    "\n",
    "    print(f\"Processing target: {target}\")\n",
    "\n",
    "    \n",
    "    y = merged_df[target]\n",
    "    \n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Fit Grid Search\n",
    "    print(f\"\\nFitting Random Forest with regularization...\")\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"\\nBest hyperparameters for {target}:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    \n",
    "    # OOB Score\n",
    "    if hasattr(best_model, 'oob_score_'):\n",
    "        print(f\"\\nOut-of-Bag R Score: {best_model.oob_score_:.4f}\")\n",
    "    \n",
    "    # CV Results\n",
    "    cv_results = grid_search.cv_results_\n",
    "    best_idx = grid_search.best_index_\n",
    "    cv_train_mse = -cv_results['mean_train_score'][best_idx]\n",
    "    cv_val_mse = -cv_results['mean_test_score'][best_idx]\n",
    "    \n",
    "    print(f\"\\nCross-Validation:\")\n",
    "    print(f\"  Train MSE: {cv_train_mse:.4f}\")\n",
    "    print(f\"  Val MSE:   {cv_val_mse:.4f}\")\n",
    "    print(f\"  Ratio:     {cv_val_mse/cv_train_mse:.2f}\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = best_model.predict(X_train_scaled)\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    overfitting_gap = train_r2 - test_r2\n",
    "    \n",
    "    \n",
    "    # Store results\n",
    "    results_rf2.append({\n",
    "        'target': target,\n",
    "        'model_type': 'Random Forest (Regularized)',\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'oob_score': best_model.oob_score_ if hasattr(best_model, 'oob_score_') else None,\n",
    "        'cv_train_mse': cv_train_mse,\n",
    "        'cv_val_mse': cv_val_mse,\n",
    "        'best_model': best_model,\n",
    "        'scaler': scaler\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics for {target}:\")\n",
    "    print(f\"\\nTraining Set:\")\n",
    "    print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"  MAE:  {train_mae:.4f}\")\n",
    "    print(f\"  R:   {train_r2:.4f}\")\n",
    "    print(f\"\\nTest Set:\")\n",
    "    print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  MAE:  {test_mae:.4f}\")\n",
    "    print(f\"  R:   {test_r2:.4f}\")\n",
    "    print(f\"\\nOverfitting Analysis:\")\n",
    "    print(f\"  Gap: {overfitting_gap:.4f}\")\n",
    "    \n",
    "    if overfitting_gap < 0.15:\n",
    "        print(\"   Good generalization\")\n",
    "    elif overfitting_gap < 0.3:\n",
    "        print(\"  Moderate overfitting\")\n",
    "    else:\n",
    "        print(\"  High overfitting - features may not capture target well\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_rf2_df = pd.DataFrame(results_rf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "592703d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>model_type</th>\n",
       "      <th>best_params</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>overfitting_gap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>cv_train_mse</th>\n",
       "      <th>cv_val_mse</th>\n",
       "      <th>best_model</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loudness</td>\n",
       "      <td>Random Forest (Regularized)</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "      <td>2.452549</td>\n",
       "      <td>3.210250</td>\n",
       "      <td>1.727980</td>\n",
       "      <td>2.470821</td>\n",
       "      <td>0.719799</td>\n",
       "      <td>0.484702</td>\n",
       "      <td>0.235097</td>\n",
       "      <td>0.415126</td>\n",
       "      <td>6.048432</td>\n",
       "      <td>12.567539</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=15, max_featu...</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>Random Forest (Regularized)</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 5, 'max_featu...</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.068637</td>\n",
       "      <td>0.035149</td>\n",
       "      <td>0.035114</td>\n",
       "      <td>0.147001</td>\n",
       "      <td>0.098986</td>\n",
       "      <td>0.048016</td>\n",
       "      <td>0.075526</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=5, max_featur...</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>Random Forest (Regularized)</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "      <td>0.227124</td>\n",
       "      <td>0.326108</td>\n",
       "      <td>0.196808</td>\n",
       "      <td>0.286401</td>\n",
       "      <td>0.624021</td>\n",
       "      <td>0.202519</td>\n",
       "      <td>0.421502</td>\n",
       "      <td>0.217767</td>\n",
       "      <td>0.051393</td>\n",
       "      <td>0.108064</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=15, max_featu...</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liveness</td>\n",
       "      <td>Random Forest (Regularized)</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "      <td>0.126381</td>\n",
       "      <td>0.148017</td>\n",
       "      <td>0.092742</td>\n",
       "      <td>0.113351</td>\n",
       "      <td>0.375095</td>\n",
       "      <td>0.037621</td>\n",
       "      <td>0.337475</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=15, max_featu...</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tempo</td>\n",
       "      <td>Random Forest (Regularized)</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "      <td>20.043738</td>\n",
       "      <td>27.522049</td>\n",
       "      <td>15.479801</td>\n",
       "      <td>21.785006</td>\n",
       "      <td>0.590408</td>\n",
       "      <td>0.092808</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>0.075053</td>\n",
       "      <td>401.213898</td>\n",
       "      <td>905.552731</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=15, max_featu...</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>valence</td>\n",
       "      <td>Random Forest (Regularized)</td>\n",
       "      <td>{'bootstrap': True, 'max_depth': 15, 'max_feat...</td>\n",
       "      <td>0.150418</td>\n",
       "      <td>0.208919</td>\n",
       "      <td>0.123280</td>\n",
       "      <td>0.172590</td>\n",
       "      <td>0.672111</td>\n",
       "      <td>0.350824</td>\n",
       "      <td>0.321286</td>\n",
       "      <td>0.267868</td>\n",
       "      <td>0.022311</td>\n",
       "      <td>0.051362</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=15, max_featu...</td>\n",
       "      <td>StandardScaler()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target                   model_type  \\\n",
       "0          loudness  Random Forest (Regularized)   \n",
       "1       speechiness  Random Forest (Regularized)   \n",
       "2  instrumentalness  Random Forest (Regularized)   \n",
       "3          liveness  Random Forest (Regularized)   \n",
       "4             tempo  Random Forest (Regularized)   \n",
       "5           valence  Random Forest (Regularized)   \n",
       "\n",
       "                                         best_params  train_rmse  test_rmse  \\\n",
       "0  {'bootstrap': True, 'max_depth': 15, 'max_feat...    2.452549   3.210250   \n",
       "1  {'bootstrap': True, 'max_depth': 5, 'max_featu...    0.065832   0.068637   \n",
       "2  {'bootstrap': True, 'max_depth': 15, 'max_feat...    0.227124   0.326108   \n",
       "3  {'bootstrap': True, 'max_depth': 15, 'max_feat...    0.126381   0.148017   \n",
       "4  {'bootstrap': True, 'max_depth': 15, 'max_feat...   20.043738  27.522049   \n",
       "5  {'bootstrap': True, 'max_depth': 15, 'max_feat...    0.150418   0.208919   \n",
       "\n",
       "   train_mae   test_mae  train_r2   test_r2  overfitting_gap  oob_score  \\\n",
       "0   1.727980   2.470821  0.719799  0.484702         0.235097   0.415126   \n",
       "1   0.035149   0.035114  0.147001  0.098986         0.048016   0.075526   \n",
       "2   0.196808   0.286401  0.624021  0.202519         0.421502   0.217767   \n",
       "3   0.092742   0.113351  0.375095  0.037621         0.337475   0.036069   \n",
       "4  15.479801  21.785006  0.590408  0.092808         0.497600   0.075053   \n",
       "5   0.123280   0.172590  0.672111  0.350824         0.321286   0.267868   \n",
       "\n",
       "   cv_train_mse  cv_val_mse  \\\n",
       "0      6.048432   12.567539   \n",
       "1      0.004329    0.004701   \n",
       "2      0.051393    0.108064   \n",
       "3      0.015379    0.024194   \n",
       "4    401.213898  905.552731   \n",
       "5      0.022311    0.051362   \n",
       "\n",
       "                                          best_model            scaler  \n",
       "0  (DecisionTreeRegressor(max_depth=15, max_featu...  StandardScaler()  \n",
       "1  (DecisionTreeRegressor(max_depth=5, max_featur...  StandardScaler()  \n",
       "2  (DecisionTreeRegressor(max_depth=15, max_featu...  StandardScaler()  \n",
       "3  (DecisionTreeRegressor(max_depth=15, max_featu...  StandardScaler()  \n",
       "4  (DecisionTreeRegressor(max_depth=15, max_featu...  StandardScaler()  \n",
       "5  (DecisionTreeRegressor(max_depth=15, max_featu...  StandardScaler()  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_rf2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07575339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved loudness model\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "for target in ['loudness']:  \n",
    "    # Get model data from results_df\n",
    "    row = results_df[results_df['target'] == target].iloc[0]  #  Add .iloc[0] to get the row as a Series\n",
    "    \n",
    "    # Create directory\n",
    "    (root / 'models' / target).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save model and scaler\n",
    "    joblib.dump(row['best_model'], root / 'models' / target / f'rf_{target}_model.pkl')\n",
    "    \n",
    "    # Save metadata - convert all values to native Python types\n",
    "    metadata = {\n",
    "        'target': target,\n",
    "        'model_type': 'RandomForest',\n",
    "        'trained_date': datetime.now().strftime('%Y-%m-%d'),\n",
    "        'hyperparameters': row['best_params'],  # This is already a dict\n",
    "        'performance': {\n",
    "            'test_r2': float(row['test_r2']),      #  Convert to float\n",
    "            'test_rmse': float(row['test_rmse'])   #  Convert to float\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(root / 'models' / target / f'rf_{target}_metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\" Saved {target} model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef7697",
   "metadata": {},
   "source": [
    "## **LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5c24d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\zoro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\zoro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from lightgbm) (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\zoro\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from lightgbm) (1.16.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9180bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHTGBM TRAINING FOR POOR-PERFORMING FEATURES\n",
      "Training LightGBM for: SPEECHINESS\n",
      "\n",
      "Performing 5-fold cross-validation...\n",
      "CV Train MSE: 0.0007\n",
      "CV Val MSE:   0.0050\n",
      "CV Train R:  0.8538\n",
      "CV Val R:    -0.0187\n",
      "CV Ratio:     6.82\n",
      "\n",
      "Training final model...\n",
      "PERFORMANCE METRICS\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.0275\n",
      "  MAE:  0.0132\n",
      "  R:   0.8508\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.0667\n",
      "  MAE:  0.0331\n",
      "  R:   0.1487\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.7020\n",
      "  High overfitting\n",
      "Training LightGBM for: INSTRUMENTALNESS\n",
      "\n",
      "Performing 5-fold cross-validation...\n",
      "CV Train MSE: 0.0085\n",
      "CV Val MSE:   0.1099\n",
      "CV Train R:  0.9381\n",
      "CV Val R:    0.1945\n",
      "CV Ratio:     12.95\n",
      "\n",
      "Training final model...\n",
      "PERFORMANCE METRICS\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.1025\n",
      "  MAE:  0.0694\n",
      "  R:   0.9234\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.3246\n",
      "  MAE:  0.2646\n",
      "  R:   0.2098\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.7136\n",
      "  High overfitting\n",
      "Training LightGBM for: LIVENESS\n",
      "\n",
      "Performing 5-fold cross-validation...\n",
      "CV Train MSE: 0.0030\n",
      "CV Val MSE:   0.0260\n",
      "CV Train R:  0.8831\n",
      "CV Val R:    -0.0179\n",
      "CV Ratio:     8.69\n",
      "\n",
      "Training final model...\n",
      "PERFORMANCE METRICS\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.0579\n",
      "  MAE:  0.0325\n",
      "  R:   0.8687\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.1560\n",
      "  MAE:  0.1144\n",
      "  R:   -0.0696\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.9383\n",
      "  High overfitting\n",
      "Training LightGBM for: VALENCE\n",
      "\n",
      "Performing 5-fold cross-validation...\n",
      "CV Train MSE: 0.0037\n",
      "CV Val MSE:   0.0522\n",
      "CV Train R:  0.9466\n",
      "CV Val R:    0.2415\n",
      "CV Ratio:     14.16\n",
      "\n",
      "Training final model...\n",
      "PERFORMANCE METRICS\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 0.0690\n",
      "  MAE:  0.0501\n",
      "  R:   0.9310\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 0.2065\n",
      "  MAE:  0.1654\n",
      "  R:   0.3660\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.5650\n",
      "  High overfitting\n",
      "Training LightGBM for: TEMPO\n",
      "\n",
      "Performing 5-fold cross-validation...\n",
      "CV Train MSE: 75.2926\n",
      "CV Val MSE:   982.5991\n",
      "CV Train R:  0.9231\n",
      "CV Val R:    -0.0043\n",
      "CV Ratio:     13.05\n",
      "\n",
      "Training final model...\n",
      "PERFORMANCE METRICS\n",
      "\n",
      "Training Set:\n",
      "  RMSE: 10.0453\n",
      "  MAE:  7.1583\n",
      "  R:   0.8971\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 28.2254\n",
      "  MAE:  21.7675\n",
      "  R:   0.0458\n",
      "\n",
      "Overfitting Analysis:\n",
      "  Gap: 0.8513\n",
      "  High overfitting\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# CONFIGURATION\n",
    "\n",
    "\n",
    "# Targets to train (the poor performers from RF/SVR)\n",
    "targets_to_train = ['speechiness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "\n",
    "def get_lgbm_model():\n",
    "    \"\"\"Returns a configured LightGBM model\"\"\"\n",
    "    return LGBMRegressor(\n",
    "        n_estimators=1000,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.01,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=42,\n",
    "        verbose=-1  # Suppress training output\n",
    "    )\n",
    "\n",
    "\n",
    "# TRAINING AND EVALUATION\n",
    "\n",
    "\n",
    "# Store results\n",
    "lgbm_results = []\n",
    "\n",
    "\n",
    "print(\"LIGHTGBM TRAINING FOR POOR-PERFORMING FEATURES\")\n",
    "\n",
    "\n",
    "for target in targets_to_train:\n",
    "    print(f\"Training LightGBM for: {target.upper()}\")\n",
    "\n",
    "    y = merged_df[target]\n",
    "    \n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    # Initialize model\n",
    "    lgbm_model = get_lgbm_model()\n",
    "    \n",
    "    # Cross-validation\n",
    "    print(\"\\nPerforming 5-fold cross-validation...\")\n",
    "    cv_results = cross_validate(\n",
    "        lgbm_model, \n",
    "        X_train_scaled, \n",
    "        y_train,\n",
    "        cv=5,\n",
    "        scoring=['neg_mean_squared_error', 'r2'],\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cv_train_mse = -cv_results['train_neg_mean_squared_error'].mean()\n",
    "    cv_val_mse = -cv_results['test_neg_mean_squared_error'].mean()\n",
    "    cv_train_r2 = cv_results['train_r2'].mean()\n",
    "    cv_val_r2 = cv_results['test_r2'].mean()\n",
    "    \n",
    "    print(f\"CV Train MSE: {cv_train_mse:.4f}\")\n",
    "    print(f\"CV Val MSE:   {cv_val_mse:.4f}\")\n",
    "    print(f\"CV Train R:  {cv_train_r2:.4f}\")\n",
    "    print(f\"CV Val R:    {cv_val_r2:.4f}\")\n",
    "    print(f\"CV Ratio:     {cv_val_mse/cv_train_mse:.2f}\")\n",
    "    \n",
    "    # Train final model\n",
    "    print(\"\\nTraining final model...\")\n",
    "    lgbm_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = lgbm_model.predict(X_train_scaled)\n",
    "    y_test_pred = lgbm_model.predict(X_test_scaled)\n",
    "    \n",
    "    # Training metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Test metrics\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Overfitting analysis\n",
    "    overfitting_gap = train_r2 - test_r2\n",
    "    \n",
    "    # Print results\n",
    "    print(\"PERFORMANCE METRICS\")\n",
    "    print(\"\\nTraining Set:\")\n",
    "    print(f\"  RMSE: {train_rmse:.4f}\")\n",
    "    print(f\"  MAE:  {train_mae:.4f}\")\n",
    "    print(f\"  R:   {train_r2:.4f}\")\n",
    "    \n",
    "    print(\"\\nTest Set:\")\n",
    "    print(f\"  RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"  MAE:  {test_mae:.4f}\")\n",
    "    print(f\"  R:   {test_r2:.4f}\")\n",
    "    \n",
    "    print(f\"\\nOverfitting Analysis:\")\n",
    "    print(f\"  Gap: {overfitting_gap:.4f}\")\n",
    "    if overfitting_gap < 0.1:\n",
    "        print(\"   Good generalization\")\n",
    "    elif overfitting_gap < 0.2:\n",
    "        print(\"  Moderate overfitting\")\n",
    "    else:\n",
    "        print(\"  High overfitting\")\n",
    "    \n",
    "\n",
    "    # Store results\n",
    "    lgbm_results.append({\n",
    "        'target': target,\n",
    "        'model_type': 'LightGBM',\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'cv_train_mse': cv_train_mse,\n",
    "        'cv_val_mse': cv_val_mse,\n",
    "        'cv_train_r2': cv_train_r2,\n",
    "        'cv_val_r2': cv_val_r2,\n",
    "        'best_model': lgbm_model\n",
    "    })\n",
    "\n",
    "lgbm_results_df = pd.DataFrame(lgbm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e194ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ensemble for: VALENCE\n",
      "Ensemble R: 0.3680\n",
      "RF R: 0.3769\n",
      "XGB R: 0.3366\n",
      "SVR R: 0.3206\n",
      "Training Ensemble for: TEMPO\n",
      "Ensemble R: 0.0726\n",
      "RF R: 0.0815\n",
      "XGB R: 0.0151\n",
      "SVR R: 0.0534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Focus on the two most promising targets\n",
    "for target in ['valence', 'tempo']:\n",
    "    print(f\"Training Ensemble for: {target.upper()}\")\n",
    "    \n",
    "    y = merged_df[target]\n",
    "    \n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Create models\n",
    "    rf = RandomForestRegressor(n_estimators=300, max_depth=12, random_state=42)\n",
    "    xgb = XGBRegressor(n_estimators=400, max_depth=6, learning_rate=0.02, random_state=42)\n",
    "    svr = SVR(C=1.0, gamma=0.01, epsilon=0.1)\n",
    "    \n",
    "    # Ensemble with weighted voting (favor XGBoost)\n",
    "    ensemble = VotingRegressor([\n",
    "        ('rf', rf),\n",
    "        ('xgb', xgb),\n",
    "        ('svr', svr)\n",
    "    ], weights=[1, 3, 1])\n",
    "    \n",
    "    # Train\n",
    "    ensemble.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = ensemble.predict(X_test_scaled)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Ensemble R: {r2:.4f}\")\n",
    "    \n",
    "    # Compare with individual models\n",
    "    for name, model in [('RF', rf), ('XGB', xgb), ('SVR', svr)]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        r2_ind = r2_score(y_test, model.predict(X_test_scaled))\n",
    "        print(f\"{name} R: {r2_ind:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
